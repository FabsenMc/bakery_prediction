# Baseline Model
Für unser Baseline Model haben wir zunächst probiert mit Hilfe einer linearen Regression die aussagekräftigsten Features für ein neuronales Netz zu ermitteln. Dafür haben wir schrittweise Features in die lineare Regression aufgenommen und anhand des R-Quadrat geprüft, inwiefern sich die erklärte Varianz durch den Einsatz von Features, sowie von Features in Wechselwirkung zueinander sowie durch Polynomisierung der Features erhöht. Exemplarisch für diese Bemühungen, haben wir den ersten Teil des Skripts noch so dargestellt.
Wir haben relativ schnell festgestellt, dass wir so an unsere Grenzen stoßen, da es doch deutlich schwerer als gedacht ist, den Überblick über die bereits eingesetzten Variablen, sowie schon eingesetzte Wechselwirkungen zu behalten. Daher haben wir nach einer automatisierten Möglichkeit gesucht, die bestmöglichen Features für unser Modell auszuwählen. Dafür haben wir uns zunächst für einen Algorithmus entschieden, der die Features mit der größten Aussagekraft auswählen sollte.  Dieser Algorithmus sollte anhand der Trainingsdaten schrittweise Features für das Modell auswählen in dem er die innerhalb festgelegter Grenzen Merkmale aufnimmt oder entfernt. Das Merkmal mit dem kleinsten p-Wert (best_pval) wird ausgewählt und, falls dieser p-Wert unterhalb des Schwellenwerts threshold_in liegt, zur included-Liste hinzugefügt. Die p-Werte der Merkmale werden berechnet und das Merkmal mit dem größten p-Wert (worst_pval) wird identifiziert.
Falls dieser p-Wert oberhalb des Schwellenwerts threshold_out liegt, wird das entsprechende Merkmal aus der included-Liste entfernt.
Mithilfe der so ausgewählten Features haben wir dann zunächst lineare Modelle aufgestellt und deren Vorhersagekraft mithilfe verschiedener Validierunsmetriken getestet. Da hierbei relativ schlechte Werte (R-Quadrat: 0,10; MAPE:65%) resultierten, haben wir nach weiteren Algorithmusmöglichkeiten gesucht. Wir haben uns hier für den Random Forest regressor entschieden. Dieser beinhaltet nicht nur die Selektion der besten Parameter, sondern auch ein Hyperparametertuning. So das für uns auch ersichtlich war in welche Richtung sich die Aussagekraft unseres Modells bei entsprechendem Hyperparametertuning im neuronalen Netz entwickeln könnte. Wir haben, wie im zuvor genutzten Algorithmus, anhand der Trainingsdaten die aussagekräftigsten Parameter auswählen lassen. Da im Random Forest Regressor jedoch, ohne jede weitere Einschränkung alle vorhandenen Paramter optimiert werden, haben wir willkürlich festegelegt, dass die besten 10 Parameter gewählt werden sollten. Mithilfe der GridSearchCV wurde dann das beste Modell erstellt, dass anhand zuvor definierten Hyperparameter (n_estimator=Anzahl Bäume; max_features=Maximale Anzahl der Merkmale, die bei jedem split berücksichtigt werden sollte; max_depth= Maximale Tiefe der Bäume), zu finden war. Dieses Modell hat ein R-Quadrat von 0.78 erzeugt. Eingestzet in eine einfache lineare Regression, habt diese Features weiterhin einen relativ geringen Erklärungsgehalt. Da aber die Hyperparamter im neuronalen Netz ohnehin durch uns verbessert werden sollten, haben wir uns entschlossen mit diesen Parametern weiter in das neuronale Netz zu gehen. 
