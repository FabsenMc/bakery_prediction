{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pakete und Dateien einladen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as smf\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "import chardet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vorbereitung der zusätzlichen Datensätze\n",
    "Anpassungen des Verbraucherpreisindex-Datensatz "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSV Datein in dataframes einladen und erste Zeilen aller DF ausgeben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Datum  KielerWoche\n",
      "0  2012-06-16            1\n",
      "1  2012-06-17            1\n",
      "2  2012-06-18            1\n",
      "3  2012-06-19            1\n",
      "4  2012-06-20            1\n",
      "        Datum  Warengruppe      Umsatz\n",
      "0  2013-07-01            1  148.828353\n",
      "1  2013-07-02            1  159.793757\n",
      "2  2013-07-03            1  111.885594\n",
      "3  2013-07-04            1  168.864941\n",
      "4  2013-07-05            1  171.280754\n",
      "        Datum  Bewoelkung  Temperatur  Windgeschwindigkeit  Wettercode\n",
      "0  2012-01-01         8.0      9.8250                   14        58.0\n",
      "1  2012-01-02         7.0      7.4375                   12         NaN\n",
      "2  2012-01-03         8.0      5.5375                   18        63.0\n",
      "3  2012-01-04         4.0      5.6875                   19        80.0\n",
      "4  2012-01-05         6.0      5.3000                   23        80.0\n",
      "   Wettercode                             Beschreibung\n",
      "0           0  Bewoelkungsentwicklung nicht beobachtet\n",
      "1           1                     Bewoelkung abnehmend\n",
      "2           2                  Bewoelkung unveraendert\n",
      "3           3                     Bewoelkung zunehmend\n",
      "4           4  Sicht durch Rauch oder Asche vermindert\n",
      "        Datum  FerienSH  Feiertag\n",
      "0  01.01.2012         1         1\n",
      "1  02.01.2012         1         0\n",
      "2  03.01.2012         1         0\n",
      "3  04.01.2012         1         0\n",
      "4  05.01.2012         1         0\n",
      "        Datum    Uhrzeit Heim_Auswärts\n",
      "0  2012-08-25  16:00 Uhr             A\n",
      "1  2012-09-05  20:15 Uhr             A\n",
      "2  2012-09-12  20:15 Uhr             H\n",
      "3  2012-09-16  17:30 Uhr             A\n",
      "4  2012-09-25  19:30 Uhr             H\n",
      "        Datum  Umschlag\n",
      "0  2013-02-28         1\n",
      "1  2013-03-01         1\n",
      "2  2013-03-02         1\n",
      "3  2013-03-03         1\n",
      "4  2014-02-27         1\n",
      "        Datum  Weihnachtsmarkt\n",
      "0  2013-11-25                1\n",
      "1  2013-11-26                1\n",
      "2  2013-11-27                1\n",
      "3  2013-11-28                1\n",
      "4  2013-11-29                1\n"
     ]
    }
   ],
   "source": [
    "url1 = \"https://raw.githubusercontent.com/FabsenMc/bakery_prediction/main/0_DataPreparation/kiwo.csv\"\n",
    "url2 = \"https://raw.githubusercontent.com/FabsenMc/bakery_prediction/main/0_DataPreparation/umsatzdaten_gekuerzt.csv\"\n",
    "url3 = \"https://raw.githubusercontent.com/FabsenMc/bakery_prediction/main/0_DataPreparation/wetter.csv\"\n",
    "url4 = \"https://raw.githubusercontent.com/FabsenMc/bakery_prediction/main/0_DataPreparation/Wettercodes.csv\"\n",
    "url5 = \"https://raw.githubusercontent.com/FabsenMc/bakery_prediction/main/0_DataPreparation/fuf_v2.csv\"\n",
    "url6 = \"https://raw.githubusercontent.com/FabsenMc/bakery_prediction/main/0_DataPreparation/thw-kiel-spieltage.csv\"\n",
    "url7 = \"https://raw.githubusercontent.com/FabsenMc/bakery_prediction/main/0_DataPreparation/kieler_umschlag.csv\"\n",
    "url8 = \"https://raw.githubusercontent.com/FabsenMc/bakery_prediction/main/0_DataPreparation/weihnachtsmarkt.csv\"\n",
    "\n",
    "# Überführen der Daten in DataFrames\n",
    "daten = pd.read_csv(url1) # Daten der Kiwo\n",
    "umswar = pd.read_csv(url2) # Umsätze der Warengruppen\n",
    "wetter = pd.read_csv(url3) # Wetterdaten der Kiwos\n",
    "wetterc = pd.read_csv(url4) # Wettercodes\n",
    "ferien = pd.read_csv(url5) # Feriendaten\n",
    "thw = pd.read_csv(url6) # THW Kiel Spieltage\n",
    "kium = pd.read_csv(url7) # Kieler Umschlag Tage\n",
    "weima = pd.read_csv(url8) # Weihnachtsmarkt Tage\n",
    "\n",
    "# Anzeige der ersten Zeilen der DataFrames\n",
    "print(daten.head()) # Ausgabe der ersten 5 Zeilen\n",
    "print(umswar.head()) # Ausgabe der ersten 5 Zeilen \n",
    "print(wetter.head()) # Ausgabe der ersten 5 Zeilen\n",
    "print(wetterc.head()) # Ausgabe der ersten 5 Zeilen\n",
    "print(ferien.head()) # Ausgabe der ersten 5 Zeilen\n",
    "print(thw.head()) # Ausgabe der ersten 5 Zeilen\n",
    "print(kium.head()) # Ausgabe der ersten 5 Zeilen\n",
    "print(weima.head()) # Ausgabe der ersten 5 Zeilen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configurieren der Datenformate und mergen der DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Datum  KielerWoche  Warengruppe  Umsatz  Bewoelkung  Temperatur  \\\n",
      "0  2012-01-01          NaN          NaN     NaN         8.0      9.8250   \n",
      "1  2012-01-02          NaN          NaN     NaN         7.0      7.4375   \n",
      "2  2012-01-03          NaN          NaN     NaN         8.0      5.5375   \n",
      "3  2012-01-04          NaN          NaN     NaN         4.0      5.6875   \n",
      "4  2012-01-05          NaN          NaN     NaN         6.0      5.3000   \n",
      "\n",
      "   Windgeschwindigkeit  Wettercode                    Beschreibung  FerienSH  \\\n",
      "0                 14.0        58.0  leichter Spruehregen mit Regen       1.0   \n",
      "1                 12.0         NaN                             NaN       1.0   \n",
      "2                 18.0        63.0     durchgehend maessiger Regen       1.0   \n",
      "3                 19.0        80.0           leichter Regenschauer       1.0   \n",
      "4                 23.0        80.0           leichter Regenschauer       1.0   \n",
      "\n",
      "   Feiertag Uhrzeit Heim_Auswärts  Umschlag  Weihnachtsmarkt  \n",
      "0       1.0     NaN           NaN       NaN              NaN  \n",
      "1       0.0     NaN           NaN       NaN              NaN  \n",
      "2       0.0     NaN           NaN       NaN              NaN  \n",
      "3       0.0     NaN           NaN       NaN              NaN  \n",
      "4       0.0     NaN           NaN       NaN              NaN  \n"
     ]
    }
   ],
   "source": [
    "# Convert the date format from DD.MM.YYYY to MM/DD/YYYY\n",
    "ferien['Datum'] = pd.to_datetime(ferien['Datum'], dayfirst=True).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Die 3 DataFrames zusammenführen (mergen) in einen neuen gemeinsamen DataFrame mit der Methode \"outer\"\n",
    "dataf = daten.merge(umswar, on=\"Datum\", how = \"outer\") \\\n",
    "             .merge(wetter, on=\"Datum\", how = \"outer\") \\\n",
    "             .merge(wetterc, on=\"Wettercode\", how = \"left\") \\\n",
    "             .merge(ferien, on=\"Datum\", how = \"outer\") \\\n",
    "             .merge(thw, on=\"Datum\", how = \"outer\") \\\n",
    "             .merge(kium, on=\"Datum\", how = \"outer\") \\\n",
    "             .merge(weima, on=\"Datum\", how = \"outer\")\n",
    "\n",
    "# Ausgabe der ersten 5 Zeilen des neuen DataFrames\n",
    "print(dataf.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Datum  KielerWoche  Warengruppe  Umsatz  Bewoelkung  Temperatur  \\\n",
      "0 2012-01-01          NaN          NaN     NaN         8.0      9.8250   \n",
      "1 2012-01-02          NaN          NaN     NaN         7.0      7.4375   \n",
      "2 2012-01-03          NaN          NaN     NaN         8.0      5.5375   \n",
      "3 2012-01-04          NaN          NaN     NaN         4.0      5.6875   \n",
      "4 2012-01-05          NaN          NaN     NaN         6.0      5.3000   \n",
      "\n",
      "   Windgeschwindigkeit  Wettercode                    Beschreibung  FerienSH  \\\n",
      "0                 14.0        58.0  leichter Spruehregen mit Regen       1.0   \n",
      "1                 12.0         NaN                             NaN       1.0   \n",
      "2                 18.0        63.0     durchgehend maessiger Regen       1.0   \n",
      "3                 19.0        80.0           leichter Regenschauer       1.0   \n",
      "4                 23.0        80.0           leichter Regenschauer       1.0   \n",
      "\n",
      "   Feiertag Uhrzeit Heim_Auswärts  Umschlag  Weihnachtsmarkt  Regen  \\\n",
      "0       1.0     NaN           NaN       NaN              NaN      1   \n",
      "1       0.0     NaN           NaN       NaN              NaN      0   \n",
      "2       0.0     NaN           NaN       NaN              NaN      1   \n",
      "3       0.0     NaN           NaN       NaN              NaN      1   \n",
      "4       0.0     NaN           NaN       NaN              NaN      1   \n",
      "\n",
      "   Wochentag_MDMDFSS  Wochenende  Jahreszeit_FSHW Temperatur_Kategorie  \n",
      "0                  6           1                4              Niedrig  \n",
      "1                  0           0                4              Niedrig  \n",
      "2                  1           0                4              Niedrig  \n",
      "3                  2           0                4              Niedrig  \n",
      "4                  3           0                4              Niedrig  \n"
     ]
    }
   ],
   "source": [
    "# Hinzufügen einer zusätzlichen Spalte Regen ja/nein\n",
    "dataf[\"Regen\"] = dataf[\"Beschreibung\"].str.contains(\"Regen\", case=False, na=False)\n",
    "dataf[\"Regen\"] = dataf[\"Regen\"].map({True: 1, False: 0})\n",
    "\n",
    "# Hinzufügen einer zusätzlichen Spalte mit den Wochentagen\n",
    "dataf[\"Datum\"] = pd.to_datetime(dataf[\"Datum\"])\n",
    "dataf[\"Wochentag_MDMDFSS\"] = dataf[\"Datum\"].dt.weekday\n",
    "#dataf[\"Wochentag\"] = dataf[\"Wochentag\"].map({0: \"Montag\", 1: \"Dienstag\", 2: \"Mittwoch\", 3: \"Donnerstag\", 4: \"Freitag\", 5: \"Samstag\", 6: \"Sonntag\"}) #-> der ML Algorythmus kann ja nur mit Zahlen umgehen\n",
    "\n",
    "# Hinzufügen einer zusätzlichen Spalte mit den Wochenenden\n",
    "dataf[\"Wochenende\"] = dataf[\"Wochentag_MDMDFSS\"].map({0 : 0, 1 : 0, 2 : 0, 3 : 0, 4 : 0, 5 : 1, 6 : 1})\n",
    "\n",
    "# Hinzufügen einer zusätzlichen Spalte mit den Jahreszeiten Frühling Sommer Herbst und Winter (FSHW) in Abhängigkeit des Datums\n",
    "dataf[\"Jahreszeit_FSHW\"] = dataf[\"Datum\"].dt.month\n",
    "dataf[\"Jahreszeit_FSHW\"] = dataf[\"Datum\"].dt.month.map({1: 4, 2: 4, 3: 1, 4: 1, 5: 1, 6: 2, 7: 2, 8: 2, 9: 3, 10: 3, 11: 3, 12: 4})\n",
    "\n",
    "# Hinzufügen einer zusätzlichen Spalte Temperatur Kategorie # min -10, max: 32\n",
    "if 'Temperatur_Kategorie' in dataf.columns:\n",
    "    dataf.drop(columns=['Temperatur_Kategorie'], inplace=True)\n",
    "# Define the bin edges\n",
    "bins = [-10, 10, 20, 35]\n",
    "# Define the bin labels\n",
    "labels = ['Niedrig', 'Mittel', 'Hoch']\n",
    "\n",
    "# Use pd.cut() to create the new column \"Temperatur_Kategorie\"\n",
    "dataf['Temperatur_Kategorie'] = pd.cut(dataf['Temperatur'], bins=bins, labels=labels)\n",
    "\n",
    "# Ausgabe der ersten 5 Zeilen des gemergten DataFrames\n",
    "print(dataf.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speichern des DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = os.getcwd()\n",
    "\n",
    "dataf.to_csv(f\"{current_directory}/dataf.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Einladen des DFs, Splitting des DF in Trainings- und Validierungsdaten und Abspeichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Datum  KielerWoche  Warengruppe  Umsatz  Bewoelkung  Temperatur  \\\n",
      "0  2012-01-01          NaN          NaN     NaN         8.0      9.8250   \n",
      "1  2012-01-02          NaN          NaN     NaN         7.0      7.4375   \n",
      "2  2012-01-03          NaN          NaN     NaN         8.0      5.5375   \n",
      "3  2012-01-04          NaN          NaN     NaN         4.0      5.6875   \n",
      "4  2012-01-05          NaN          NaN     NaN         6.0      5.3000   \n",
      "\n",
      "   Windgeschwindigkeit  Wettercode                    Beschreibung  FerienSH  \\\n",
      "0                 14.0        58.0  leichter Spruehregen mit Regen       1.0   \n",
      "1                 12.0         NaN                             NaN       1.0   \n",
      "2                 18.0        63.0     durchgehend maessiger Regen       1.0   \n",
      "3                 19.0        80.0           leichter Regenschauer       1.0   \n",
      "4                 23.0        80.0           leichter Regenschauer       1.0   \n",
      "\n",
      "   Feiertag Uhrzeit Heim_Auswärts  Umschlag  Weihnachtsmarkt  Regen  \\\n",
      "0       1.0     NaN           NaN       NaN              NaN      1   \n",
      "1       0.0     NaN           NaN       NaN              NaN      0   \n",
      "2       0.0     NaN           NaN       NaN              NaN      1   \n",
      "3       0.0     NaN           NaN       NaN              NaN      1   \n",
      "4       0.0     NaN           NaN       NaN              NaN      1   \n",
      "\n",
      "   Wochentag_MDMDFSS  Wochenende  Jahreszeit_FSHW Temperatur_Kategorie  \n",
      "0                  6           1                4              Niedrig  \n",
      "1                  0           0                4              Niedrig  \n",
      "2                  1           0                4              Niedrig  \n",
      "3                  2           0                4              Niedrig  \n",
      "4                  3           0                4              Niedrig  \n",
      "Training dataset dimensions: (7523, 20)\n",
      "Validation dataset dimensions: (1849, 20)\n"
     ]
    }
   ],
   "source": [
    "# Laden des Dataframes -> Gibt es hier ein bessere Version?\n",
    "dataf = pd.read_csv('https://raw.githubusercontent.com/FabsenMc/bakery_prediction/main/0_DataPreparation/dataf.csv')\n",
    "print(dataf.head())\n",
    "\n",
    "#DF nach Datum sortieren\n",
    "dataf = dataf.sort_values(by='Datum')\n",
    "\n",
    "# Definieren der Datumsgrenzen\n",
    "train_start_date = '2013-07-01'\n",
    "train_end_date = '2017-07-31'\n",
    "validation_end_date = '2018-07-31'\n",
    "\n",
    "# Splitten der Daten basierend auf den Datumsgrenzen\n",
    "train_data = dataf[(dataf['Datum']>= train_start_date) & (dataf['Datum'] <= train_end_date)]\n",
    "validation_data = dataf[(dataf['Datum'] > train_end_date) & (dataf['Datum'] <= validation_end_date)]\n",
    "\n",
    "# Überprüfen der Dimensionen der Datensätze\n",
    "print(\"Training dataset dimensions:\", train_data.shape)\n",
    "print(\"Validation dataset dimensions:\", validation_data.shape)\n",
    "\n",
    "#Abspeichern der Datensätze als CSV\n",
    "#dataf.to_csv('dataf.csv', index=False)\n",
    "train_data.to_csv (f\"{current_directory}/train_data.csv\", index=False)\n",
    "validation_data.to_csv(f\"{current_directory}/validation_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 7523 entries, 547 to 8066\n",
      "Data columns (total 20 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Datum                 7523 non-null   object \n",
      " 1   KielerWoche           178 non-null    float64\n",
      " 2   Warengruppe           7493 non-null   float64\n",
      " 3   Umsatz                7493 non-null   float64\n",
      " 4   Bewoelkung            7517 non-null   float64\n",
      " 5   Temperatur            7517 non-null   float64\n",
      " 6   Windgeschwindigkeit   7517 non-null   float64\n",
      " 7   Wettercode            5423 non-null   float64\n",
      " 8   Beschreibung          5423 non-null   object \n",
      " 9   FerienSH              7493 non-null   float64\n",
      " 10  Feiertag              7493 non-null   float64\n",
      " 11  Uhrzeit               693 non-null    object \n",
      " 12  Heim_Auswärts         698 non-null    object \n",
      " 13  Umschlag              80 non-null     float64\n",
      " 14  Weihnachtsmarkt       714 non-null    float64\n",
      " 15  Regen                 7523 non-null   int64  \n",
      " 16  Wochentag_MDMDFSS     7523 non-null   int64  \n",
      " 17  Wochenende            7523 non-null   int64  \n",
      " 18  Jahreszeit_FSHW       7523 non-null   int64  \n",
      " 19  Temperatur_Kategorie  7517 non-null   object \n",
      "dtypes: float64(11), int64(4), object(5)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# Analyse der gesplitteten Datasets\n",
    "\n",
    "train_data.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
