{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pakete und Dateien einladen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as smf\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSV Datein in dataframes einladen und erste Zeilen aller DF ausgeben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Datum  KielerWoche\n",
      "0  2012-06-16            1\n",
      "1  2012-06-17            1\n",
      "2  2012-06-18            1\n",
      "3  2012-06-19            1\n",
      "4  2012-06-20            1\n",
      "        Datum  Warengruppe      Umsatz\n",
      "0  2013-07-01            1  148.828353\n",
      "1  2013-07-02            1  159.793757\n",
      "2  2013-07-03            1  111.885594\n",
      "3  2013-07-04            1  168.864941\n",
      "4  2013-07-05            1  171.280754\n",
      "        Datum  Bewoelkung  Temperatur  Windgeschwindigkeit  Wettercode\n",
      "0  2012-01-01         8.0      9.8250                   14        58.0\n",
      "1  2012-01-02         7.0      7.4375                   12         NaN\n",
      "2  2012-01-03         8.0      5.5375                   18        63.0\n",
      "3  2012-01-04         4.0      5.6875                   19        80.0\n",
      "4  2012-01-05         6.0      5.3000                   23        80.0\n",
      "   Wettercode                             Beschreibung\n",
      "0           0  Bewoelkungsentwicklung nicht beobachtet\n",
      "1           1                     Bewoelkung abnehmend\n",
      "2           2                  Bewoelkung unveraendert\n",
      "3           3                     Bewoelkung zunehmend\n",
      "4           4  Sicht durch Rauch oder Asche vermindert\n",
      "        Datum  FerienSH  Feiertag\n",
      "0  01.01.2012         1         1\n",
      "1  02.01.2012         1         0\n",
      "2  03.01.2012         1         0\n",
      "3  04.01.2012         1         0\n",
      "4  05.01.2012         1         0\n",
      "        Datum    Uhrzeit Heim_Auswärts\n",
      "0  2012-08-25  16:00 Uhr             A\n",
      "1  2012-09-05  20:15 Uhr             A\n",
      "2  2012-09-12  20:15 Uhr             H\n",
      "3  2012-09-16  17:30 Uhr             A\n",
      "4  2012-09-25  19:30 Uhr             H\n",
      "        Datum  Umschlag\n",
      "0  2013-02-28         1\n",
      "1  2013-03-01         1\n",
      "2  2013-03-02         1\n",
      "3  2013-03-03         1\n",
      "4  2014-02-27         1\n",
      "        Datum  Weihnachtsmarkt\n",
      "0  2013-11-25                1\n",
      "1  2013-11-26                1\n",
      "2  2013-11-27                1\n",
      "3  2013-11-28                1\n",
      "4  2013-11-29                1\n",
      "   Unnamed: 0  Jahr    Monat Verbraucherpreisindex  \\\n",
      "0           0   NaN      NaN              2020=100   \n",
      "1           1  1991   Januar                  60,5   \n",
      "2           2  1991  Februar                  60,8   \n",
      "3           3  1991     März                  60,8   \n",
      "4           4  1991    April                  61,0   \n",
      "\n",
      "  Veränderung zum Vorjahresmonat Veränderung zum Vormonat  \n",
      "0                         in (%)                   in (%)  \n",
      "1                              .                        .  \n",
      "2                              .                      0,5  \n",
      "3                              .                        -  \n",
      "4                              .                      0,3  \n"
     ]
    }
   ],
   "source": [
    "url1 = \"https://raw.githubusercontent.com/FabsenMc/bakery_prediction/main/0_DataPreparation/kiwo.csv\"\n",
    "url2 = \"https://raw.githubusercontent.com/FabsenMc/bakery_prediction/main/0_DataPreparation/umsatzdaten_gekuerzt.csv\"\n",
    "url3 = \"https://raw.githubusercontent.com/FabsenMc/bakery_prediction/main/0_DataPreparation/wetter.csv\"\n",
    "url4 = \"https://raw.githubusercontent.com/FabsenMc/bakery_prediction/main/0_DataPreparation/Wettercodes.csv\"\n",
    "url5 = \"https://raw.githubusercontent.com/FabsenMc/bakery_prediction/main/0_DataPreparation/fuf_v2.csv\"\n",
    "url6 = \"https://raw.githubusercontent.com/FabsenMc/bakery_prediction/main/0_DataPreparation/thw-kiel-spieltage.csv\"\n",
    "url7 = \"https://raw.githubusercontent.com/FabsenMc/bakery_prediction/main/0_DataPreparation/kieler_umschlag.csv\"\n",
    "url8 = \"https://raw.githubusercontent.com/FabsenMc/bakery_prediction/main/0_DataPreparation/weihnachtsmarkt.csv\"\n",
    "url19 = \"https://raw.githubusercontent.com/FabsenMc/bakery_prediction/main/0_DataPreparation/Verbraucherpreisindex.csv\"\n",
    "\n",
    "# Überführen der Daten in DataFrames\n",
    "daten = pd.read_csv(url1) # Daten der Kiwo\n",
    "umswar = pd.read_csv(url2) # Umsätze der Warengruppen\n",
    "wetter = pd.read_csv(url3) # Wetterdaten der Kiwos\n",
    "wetterc = pd.read_csv(url4) # Wettercodes\n",
    "ferien = pd.read_csv(url5) # Feriendaten\n",
    "thw = pd.read_csv(url6) # THW Kiel Spieltage\n",
    "kium = pd.read_csv(url7) # Kieler Umschlag Tage\n",
    "weima = pd.read_csv(url8) # Weihnachtsmarkt Tage\n",
    "verbraucherpreisindex = pd.read_csv(url19) # Verbraucherpreisindex\n",
    "\n",
    "# Anzeige der ersten Zeilen der DataFrames\n",
    "print(daten.head()) # Ausgabe der ersten 5 Zeilen\n",
    "print(umswar.head()) # Ausgabe der ersten 5 Zeilen \n",
    "print(wetter.head()) # Ausgabe der ersten 5 Zeilen\n",
    "print(wetterc.head()) # Ausgabe der ersten 5 Zeilen\n",
    "print(ferien.head()) # Ausgabe der ersten 5 Zeilen\n",
    "print(thw.head()) # Ausgabe der ersten 5 Zeilen\n",
    "print(kium.head()) # Ausgabe der ersten 5 Zeilen\n",
    "print(weima.head()) # Ausgabe der ersten 5 Zeilen\n",
    "print(verbraucherpreisindex.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notwendige Formatierung der zusätzlichen Datensätze\n",
    "Da nach der Betrachtung der ersten Zeilen direkt auffällt, dass der Datensatz des Verbraucherpreisindex in anderem Format ist, wird dieser angepasst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame nach Formatierung:\n",
      "   Jahr    Monat  Verbraucherpreisindex\n",
      "1  1991   Januar                   60.5\n",
      "2  1991  Februar                   60.8\n",
      "3  1991     März                   60.8\n",
      "4  1991    April                   61.0\n",
      "5  1991      Mai                   61.1\n",
      "Jahr                      object\n",
      "Monat                     object\n",
      "Verbraucherpreisindex    float64\n",
      "dtype: object\n",
      "DataFrame after dropping rows for years 1991-2011:\n",
      "   Verbraucherpreisindex      Datum\n",
      "0                   90.6 2012-01-01\n",
      "1                   91.2 2012-02-01\n",
      "2                   91.7 2012-03-01\n",
      "3                   91.6 2012-04-01\n",
      "4                   91.5 2012-05-01\n"
     ]
    }
   ],
   "source": [
    "# Ersetzten der Kommas als Zahlentrennzeichen mit Punkten\n",
    "\n",
    "# Definieren der Spalten, die formatiert werden sollen\n",
    "numeric_columns = ['Verbraucherpreisindex', 'Veränderung zum Vorjahresmonat', 'Veränderung zum Vormonat']\n",
    "\n",
    "# Ersetzen der Kommas und umwandeln in numerisches Format\n",
    "#for col in numeric_columns:\n",
    "#    verbraucherpreisindex[col] = verbraucherpreisindex[col].str.replace(',', '.', regex=False) \n",
    "#    verbraucherpreisindex[col] = pd.to_numeric(verbraucherpreisindex[col], errors='coerce')\n",
    "\n",
    "print(\"DataFrame nach Formatierung:\")\n",
    "print(verbraucherpreisindex.head())\n",
    "print(verbraucherpreisindex.dtypes)\n",
    "\n",
    "# Dropen der ersten Zeile und der Spalte Unnamed, sowie den Spalten Veränderung zum Vorjahresmonat da diese nicht gebraucht werden \n",
    "#verbraucherpreisindex = verbraucherpreisindex.drop(index=0)\n",
    "#verbraucherpreisindex = verbraucherpreisindex.drop(columns=['Unnamed: 0', 'Veränderung zum Vorjahresmonat', 'Veränderung zum Vormonat'])\n",
    "#print(verbraucherpreisindex.head())\n",
    "\n",
    "# Auch die Datumsspalte muss angepasst werden, da es bisher nur zwei gibt\n",
    "month_map = {\n",
    "    'Januar': '01', 'Februar': '02', 'März': '03', 'April': '04',\n",
    "    'Mai': '05', 'Juni': '06', 'Juli': '07', 'August': '08',\n",
    "    'September': '09', 'Oktober': '10', 'November': '11', 'Dezember': '12'\n",
    "}\n",
    "# Ersetzen der Monatsnamen mit Nummern \n",
    "verbraucherpreisindex['Monat'] = verbraucherpreisindex['Monat'].map(month_map)\n",
    "\n",
    "# Erstellen einer Datumsspalte\n",
    "verbraucherpreisindex['Datum'] = verbraucherpreisindex['Jahr'].astype(str) + '-' + verbraucherpreisindex['Monat'] + '-01'\n",
    "\n",
    "# Konvertieren der Datumsspalte in Datumsformat\n",
    "verbraucherpreisindex['Datum'] = pd.to_datetime(verbraucherpreisindex['Datum'])\n",
    "\n",
    "# Drop the original \"Jahr\" and \"Monat\" columns if they are no longer needed\n",
    "verbraucherpreisindex = verbraucherpreisindex.drop(columns=['Jahr', 'Monat'])\n",
    "\n",
    "#drop der nicht benötigten Jahre\n",
    "# drop the years 1991-2011\n",
    "verbraucherpreisindex = verbraucherpreisindex[verbraucherpreisindex['Datum'].dt.year >= 2012]\n",
    "verbraucherpreisindex = verbraucherpreisindex[verbraucherpreisindex['Datum'].dt.year <2020].reset_index(drop=True)\n",
    "print(\"DataFrame after dropping rows for years 1991-2011:\")\n",
    "print(verbraucherpreisindex.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configurieren der Datenformate und mergen der DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "unconverted data remains when parsing with format \"%Y-%d-%m\": \"3\", at position 12. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Convert the date format from DD.MM.YYYY to MM/DD/YYYY\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m ferien[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDatum\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mferien\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDatum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Die 3 DataFrames zusammenführen (mergen) in einen neuen gemeinsamen DataFrame mit der Methode \"outer\"\u001b[39;00m\n\u001b[1;32m      5\u001b[0m dataf \u001b[38;5;241m=\u001b[39m daten\u001b[38;5;241m.\u001b[39mmerge(umswar, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatum\u001b[39m\u001b[38;5;124m\"\u001b[39m, how \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mouter\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m      6\u001b[0m              \u001b[38;5;241m.\u001b[39mmerge(wetter, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatum\u001b[39m\u001b[38;5;124m\"\u001b[39m, how \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mouter\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m      7\u001b[0m              \u001b[38;5;241m.\u001b[39mmerge(wetterc, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWettercode\u001b[39m\u001b[38;5;124m\"\u001b[39m, how \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m              \u001b[38;5;241m.\u001b[39mmerge(kium, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatum\u001b[39m\u001b[38;5;124m\"\u001b[39m, how \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mouter\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m     11\u001b[0m              \u001b[38;5;241m.\u001b[39mmerge(weima, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatum\u001b[39m\u001b[38;5;124m\"\u001b[39m, how \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mouter\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/tools/datetimes.py:1067\u001b[0m, in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m   1065\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mmap(cache_array)\n\u001b[1;32m   1066\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1067\u001b[0m         values \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1068\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39m_constructor(values, index\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mindex, name\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, (ABCDataFrame, abc\u001b[38;5;241m.\u001b[39mMutableMapping)):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/tools/datetimes.py:433\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;66;03m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array_strptime_with_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m objects_to_datetime64(\n\u001b[1;32m    436\u001b[0m     arg,\n\u001b[1;32m    437\u001b[0m     dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    441\u001b[0m     allow_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    442\u001b[0m )\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/tools/datetimes.py:467\u001b[0m, in \u001b[0;36m_array_strptime_with_fallback\u001b[0;34m(arg, name, utc, fmt, exact, errors)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_array_strptime_with_fallback\u001b[39m(\n\u001b[1;32m    457\u001b[0m     arg,\n\u001b[1;32m    458\u001b[0m     name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    462\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    463\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Index:\n\u001b[1;32m    464\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;124;03m    Call array_strptime, with fallback behavior depending on 'errors'.\u001b[39;00m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 467\u001b[0m     result, tz_out \u001b[38;5;241m=\u001b[39m \u001b[43marray_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tz_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    469\u001b[0m         unit \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdatetime_data(result\u001b[38;5;241m.\u001b[39mdtype)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32mstrptime.pyx:501\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mstrptime.pyx:451\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mstrptime.pyx:587\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime._parse_with_format\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: unconverted data remains when parsing with format \"%Y-%d-%m\": \"3\", at position 12. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this."
     ]
    }
   ],
   "source": [
    "# Convert the date format from DD.MM.YYYY to MM/DD/YYYY\n",
    "ferien['Datum'] = pd.to_datetime(ferien['Datum'], dayfirst=True).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Die 3 DataFrames zusammenführen (mergen) in einen neuen gemeinsamen DataFrame mit der Methode \"outer\"\n",
    "dataf = daten.merge(umswar, on=\"Datum\", how = \"outer\") \\\n",
    "             .merge(wetter, on=\"Datum\", how = \"outer\") \\\n",
    "             .merge(wetterc, on=\"Wettercode\", how = \"left\") \\\n",
    "             .merge(ferien, on=\"Datum\", how = \"outer\") \\\n",
    "             .merge(thw, on=\"Datum\", how = \"outer\") \\\n",
    "             .merge(kium, on=\"Datum\", how = \"outer\") \\\n",
    "             .merge(weima, on=\"Datum\", how = \"outer\")\n",
    "\n",
    "# Ausgabe der ersten 5 Zeilen des neuen DataFrames\n",
    "print(dataf.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Datum  KielerWoche  Warengruppe  Umsatz  Bewoelkung  Temperatur  \\\n",
      "0 2012-01-01          NaN          NaN     NaN         8.0      9.8250   \n",
      "1 2012-01-02          NaN          NaN     NaN         7.0      7.4375   \n",
      "2 2012-01-03          NaN          NaN     NaN         8.0      5.5375   \n",
      "3 2012-01-04          NaN          NaN     NaN         4.0      5.6875   \n",
      "4 2012-01-05          NaN          NaN     NaN         6.0      5.3000   \n",
      "\n",
      "   Windgeschwindigkeit  Wettercode                    Beschreibung  FerienSH  \\\n",
      "0                 14.0        58.0  leichter Spruehregen mit Regen       1.0   \n",
      "1                 12.0         NaN                             NaN       1.0   \n",
      "2                 18.0        63.0     durchgehend maessiger Regen       1.0   \n",
      "3                 19.0        80.0           leichter Regenschauer       1.0   \n",
      "4                 23.0        80.0           leichter Regenschauer       1.0   \n",
      "\n",
      "   Feiertag Uhrzeit Heim_Auswärts  Umschlag  Weihnachtsmarkt  Regen  \\\n",
      "0       1.0     NaN           NaN       NaN              NaN      1   \n",
      "1       0.0     NaN           NaN       NaN              NaN      0   \n",
      "2       0.0     NaN           NaN       NaN              NaN      1   \n",
      "3       0.0     NaN           NaN       NaN              NaN      1   \n",
      "4       0.0     NaN           NaN       NaN              NaN      1   \n",
      "\n",
      "   Wochentag_MDMDFSS  Wochenende  Jahreszeit_FSHW Temperatur_Kategorie  \n",
      "0                  6           1                4              Niedrig  \n",
      "1                  0           0                4              Niedrig  \n",
      "2                  1           0                4              Niedrig  \n",
      "3                  2           0                4              Niedrig  \n",
      "4                  3           0                4              Niedrig  \n"
     ]
    }
   ],
   "source": [
    "# Hinzufügen einer zusätzlichen Spalte Regen ja/nein\n",
    "dataf[\"Regen\"] = dataf[\"Beschreibung\"].str.contains(\"Regen\", case=False, na=False)\n",
    "dataf[\"Regen\"] = dataf[\"Regen\"].map({True: 1, False: 0})\n",
    "\n",
    "# Hinzufügen einer zusätzlichen Spalte mit den Wochentagen\n",
    "dataf[\"Datum\"] = pd.to_datetime(dataf[\"Datum\"])\n",
    "dataf[\"Wochentag_MDMDFSS\"] = dataf[\"Datum\"].dt.weekday\n",
    "#dataf[\"Wochentag\"] = dataf[\"Wochentag\"].map({0: \"Montag\", 1: \"Dienstag\", 2: \"Mittwoch\", 3: \"Donnerstag\", 4: \"Freitag\", 5: \"Samstag\", 6: \"Sonntag\"}) #-> der ML Algorythmus kann ja nur mit Zahlen umgehen\n",
    "\n",
    "# Hinzufügen einer zusätzlichen Spalte mit den Wochenenden\n",
    "dataf[\"Wochenende\"] = dataf[\"Wochentag_MDMDFSS\"].map({0 : 0, 1 : 0, 2 : 0, 3 : 0, 4 : 0, 5 : 1, 6 : 1})\n",
    "\n",
    "# Hinzufügen einer zusätzlichen Spalte mit den Jahreszeiten Frühling Sommer Herbst und Winter (FSHW) in Abhängigkeit des Datums\n",
    "dataf[\"Jahreszeit_FSHW\"] = dataf[\"Datum\"].dt.month\n",
    "dataf[\"Jahreszeit_FSHW\"] = dataf[\"Datum\"].dt.month.map({1: 4, 2: 4, 3: 1, 4: 1, 5: 1, 6: 2, 7: 2, 8: 2, 9: 3, 10: 3, 11: 3, 12: 4})\n",
    "\n",
    "# Hinzufügen einer zusätzlichen Spalte Temperatur Kategorie # min -10, max: 32\n",
    "if 'Temperatur_Kategorie' in dataf.columns:\n",
    "    dataf.drop(columns=['Temperatur_Kategorie'], inplace=True)\n",
    "# Define the bin edges\n",
    "bins = [-10, 10, 20, 35]\n",
    "# Define the bin labels\n",
    "labels = ['Niedrig', 'Mittel', 'Hoch']\n",
    "\n",
    "# Use pd.cut() to create the new column \"Temperatur_Kategorie\"\n",
    "dataf['Temperatur_Kategorie'] = pd.cut(dataf['Temperatur'], bins=bins, labels=labels)\n",
    "\n",
    "# Ausgabe der ersten 5 Zeilen des gemergten DataFrames\n",
    "print(dataf.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speichern des DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = os.getcwd()\n",
    "\n",
    "dataf.to_csv(f\"{current_directory}/dataf.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Einladen des DFs, Splitting des DF in Trainings- und Validierungsdaten und Abspeichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Datum  KielerWoche  Warengruppe  Umsatz  Bewoelkung  Temperatur  \\\n",
      "0  2012-01-01          NaN          NaN     NaN         8.0      9.8250   \n",
      "1  2012-01-02          NaN          NaN     NaN         7.0      7.4375   \n",
      "2  2012-01-03          NaN          NaN     NaN         8.0      5.5375   \n",
      "3  2012-01-04          NaN          NaN     NaN         4.0      5.6875   \n",
      "4  2012-01-05          NaN          NaN     NaN         6.0      5.3000   \n",
      "\n",
      "   Windgeschwindigkeit  Wettercode                    Beschreibung  FerienSH  \\\n",
      "0                 14.0        58.0  leichter Spruehregen mit Regen       1.0   \n",
      "1                 12.0         NaN                             NaN       1.0   \n",
      "2                 18.0        63.0     durchgehend maessiger Regen       1.0   \n",
      "3                 19.0        80.0           leichter Regenschauer       1.0   \n",
      "4                 23.0        80.0           leichter Regenschauer       1.0   \n",
      "\n",
      "   Feiertag Uhrzeit Heim_Auswärts  Umschlag  Weihnachtsmarkt  Regen  \\\n",
      "0       1.0     NaN           NaN       NaN              NaN      1   \n",
      "1       0.0     NaN           NaN       NaN              NaN      0   \n",
      "2       0.0     NaN           NaN       NaN              NaN      1   \n",
      "3       0.0     NaN           NaN       NaN              NaN      1   \n",
      "4       0.0     NaN           NaN       NaN              NaN      1   \n",
      "\n",
      "   Wochentag_MDMDFSS  Wochenende  Jahreszeit_FSHW Temperatur_Kategorie  \n",
      "0                  6           1                4              Niedrig  \n",
      "1                  0           0                4              Niedrig  \n",
      "2                  1           0                4              Niedrig  \n",
      "3                  2           0                4              Niedrig  \n",
      "4                  3           0                4              Niedrig  \n",
      "Training dataset dimensions: (7523, 20)\n",
      "Validation dataset dimensions: (1849, 20)\n"
     ]
    }
   ],
   "source": [
    "# Laden des Dataframes -> Gibt es hier ein bessere Version?\n",
    "dataf = pd.read_csv('https://raw.githubusercontent.com/FabsenMc/bakery_prediction/main/0_DataPreparation/dataf.csv')\n",
    "print(dataf.head())\n",
    "\n",
    "#DF nach Datum sortieren\n",
    "dataf = dataf.sort_values(by='Datum')\n",
    "\n",
    "# Definieren der Datumsgrenzen\n",
    "train_start_date = '2013-07-01'\n",
    "train_end_date = '2017-07-31'\n",
    "validation_end_date = '2018-07-31'\n",
    "\n",
    "# Splitten der Daten basierend auf den Datumsgrenzen\n",
    "train_data = dataf[(dataf['Datum']>= train_start_date) & (dataf['Datum'] <= train_end_date)]\n",
    "validation_data = dataf[(dataf['Datum'] > train_end_date) & (dataf['Datum'] <= validation_end_date)]\n",
    "\n",
    "# Überprüfen der Dimensionen der Datensätze\n",
    "print(\"Training dataset dimensions:\", train_data.shape)\n",
    "print(\"Validation dataset dimensions:\", validation_data.shape)\n",
    "\n",
    "#Abspeichern der Datensätze als CSV\n",
    "#dataf.to_csv('dataf.csv', index=False)\n",
    "train_data.to_csv (f\"{current_directory}/train_data.csv\", index=False)\n",
    "validation_data.to_csv(f\"{current_directory}/validation_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 7523 entries, 547 to 8066\n",
      "Data columns (total 20 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Datum                 7523 non-null   object \n",
      " 1   KielerWoche           178 non-null    float64\n",
      " 2   Warengruppe           7493 non-null   float64\n",
      " 3   Umsatz                7493 non-null   float64\n",
      " 4   Bewoelkung            7517 non-null   float64\n",
      " 5   Temperatur            7517 non-null   float64\n",
      " 6   Windgeschwindigkeit   7517 non-null   float64\n",
      " 7   Wettercode            5423 non-null   float64\n",
      " 8   Beschreibung          5423 non-null   object \n",
      " 9   FerienSH              7493 non-null   float64\n",
      " 10  Feiertag              7493 non-null   float64\n",
      " 11  Uhrzeit               693 non-null    object \n",
      " 12  Heim_Auswärts         698 non-null    object \n",
      " 13  Umschlag              80 non-null     float64\n",
      " 14  Weihnachtsmarkt       714 non-null    float64\n",
      " 15  Regen                 7523 non-null   int64  \n",
      " 16  Wochentag_MDMDFSS     7523 non-null   int64  \n",
      " 17  Wochenende            7523 non-null   int64  \n",
      " 18  Jahreszeit_FSHW       7523 non-null   int64  \n",
      " 19  Temperatur_Kategorie  7517 non-null   object \n",
      "dtypes: float64(11), int64(4), object(5)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# Analyse der gesplitteten Datasets\n",
    "\n",
    "train_data.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
