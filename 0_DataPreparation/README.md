# Data Preparation

Die Datenvorbereitung war der erste Schritt in unserem Projekt. Hier waren wir bemüht sicherzustellen, dass die verfügbaren Daten für das zukünftige Modell geeignet und von angemessener Qualität sind. Für alle folgenden Schritte hat es sich als äußerst wichtig herausgestellt, regelmäßig zu prüfen in welchem Format die einzelnen Features formatiert sind und diese gegebenfalls umzuformatieren. 

Zunächst haben wir ein Skript erstellt, um die Daten aus den verfügbaren CSV-Datein einzuladen, in einen gemeinsamen Dataframe zu überführen und in verschiedenen Art und Weisen statistisch zu untersuchen (siehe  DatasetCharacteristics). Dazu gehörten unter anderem Mean und Median, aber auch die Varianzverteilung. Zum Kombinieren der CSV-Daten mussten unter anderem die Datenformate der einzelnen CSVs angepasst werden. Durch diesen Prozess haben wir ein erstes Gefühl bekommen, wie die Daten verteilt sind und in welcher Art und Weise die verschiedenen Informationen zusammenhängen. Z.B. wurde klar, dass es einen Unterschied macht, ob die Verkaufszahlen im Bezug auf die Temperatur generell betrachtet wurde, oder ob in dieser Anschauung die jeweilige Jahreszeit in der die Temperatur gemessen wurde mit beachtet wird. Außerdem wurde klar, dass es in einigen Features fehlende Werte gab, oder die Information in schlecht zu nutzendem Format vorlag (z.B. der Wettercode als Zahl von 0-99).

Anhand dieser ersten Informationen über die Zusammenhänge zwischen den einzelnen Features haben wir erste eigene zusätzliche Features erstellt (z.B. eine eigene Spalte die die Information über den Wochentag enthält). Um die bestehenden Daten zu ergänzen, haben wir außerdem aus dem Internet zusätzliche Informationen eingeholt und in den bestehenden Dataframe eingepflegt (z.B. die Information über den Verbraucherpreisindex). Features welche in unhandlicher Art und Weise vorlagen, haben wir in angenehmere Kategorien umgewandelt. Z.B. wurde das in Zahlen vorliegende Feature für die Wetterinformation in Textbeschreibungen überführt und anschließend Kategorisiert (z.B. nach Tagen an denen es geregnet hat). Im folgenden Schritt wurden fehlende Werte in sinnvoller Art und Weise ersetzt (Imputation). Hierbei wurden die einzelnen Features auf fehlende Werte geprüft und diese dann mit dem KNN Verfahren bereinigt. Im Anschluss und zur Nachüberprüfung haben wir die Missing Values grafisch dargestellt.

Im letzten Schritt,  haben wir unseren gesamten Dataframe in einen Trainings-, Validierungs- und Testdatensatz unterteilt und als CSV Datei in unserem Repository für die weitere Verarbeitung abgespeichert.
