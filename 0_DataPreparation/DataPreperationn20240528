###          Data preparation          ###

# import libraries bpipefore start
import pandas as pd
import matplotlib.pyplot as plt
import statsmodels.formula.api as smf
import scipy.stats as stats
import numpy as np
import seaborn as sns


# Einlesen der Daten als URL
url1 = "https://raw.githubusercontent.com/FabsenMc/bakery_prediction/main/0_DataPreparation/kiwo.csv"
url2 = "https://raw.githubusercontent.com/FabsenMc/bakery_prediction/main/0_DataPreparation/umsatzdaten_gekuerzt.csv"
url3 = "https://raw.githubusercontent.com/FabsenMc/bakery_prediction/main/0_DataPreparation/wetter.csv"
url4 = "https://raw.githubusercontent.com/FabsenMc/bakery_prediction/main/0_DataPreparation/Wettercodes.csv"
url5 = "https://raw.githubusercontent.com/FabsenMc/bakery_prediction/main/0_DataPreparation/Feiertage%20SH.csv"
url6 = "https://raw.githubusercontent.com/FabsenMc/bakery_prediction/main/0_DataPreparation/thw-kiel-spieltage.csv"

# Überführen der Daten in DataFrames
daten = pd.read_csv(url1) # Daten der Kiwo
umswar = pd.read_csv(url2) # Umsätze der Warengruppen
wetter = pd.read_csv(url3) # Wetterdaten der Kiwos
wetterc = pd.read_csv(url4) # Wettercodes
thw = pd.read_csv(url6) # THW Kiel Spieltage
ferien = pd.read_csv(url6) # Feriendaten

# Anzeige der ersten Zeilen der DataFrames
print(daten.head()) # Ausgabe der ersten 5 Zeilen
print(umswar.head()) # Ausgabe der ersten 5 Zeilen 
print(wetter.head()) # Ausgabe der ersten 5 Zeilen
print(wetterc.head()) # Ausgabe der ersten 5 Zeilen
print(thw.head()) # Ausgabe der ersten 5 Zeilen
print(ferien.head()) # Ausgabe der ersten 5 Zeilen



# Die 3 DataFrames zusammenführen (mergen) in einen neuen gemeinsamen DataFrame mit der Methode "outer"
dataf = daten.merge(umswar, on="Datum", how = "outer") \
             .merge(wetter, on="Datum", how = "outer") \
             .merge(wetterc, on="Wettercode", how = "outer") \
             .merge(ferien, on="Datum", how = "outer") \
             .merge(thw, on="Datum", how = "outer")

# Ausgabe der ersten 5 Zeilen des neuen DataFrames
print(dataf.head())

## Featureengineering

# Hinzufügen einer zusätzlichen Spalte Regen ja/nein
dataf["Regen"] = dataf["Beschreibung"].str.contains("Regen", case=False, na=False)
dataf["Regen"] = dataf["Regen"].map({True: 1, False: 0})

# Hinzufügen einer zusätzlichen Spalte mit den Wochentagen
dataf["Datum"] = pd.to_datetime(dataf["Datum"])
dataf["Wochentag"] = dataf["Datum"].dt.weekday
dataf["Wochentag"] = dataf["Wochentag"].map({0: "Montag", 1: "Dienstag", 2: "Mittwoch", 3: "Donnerstag", 4: "Freitag", 5: "Samstag", 6: "Sonntag"}) #-> der ML Algorythmus kann ja nur mit Zahlen umgehen

# Hinzufügen einer zusätzlichen Spalte mit den Wochenenden
dataf["Wochenende"] = dataf["Wochentag"].map({"Montag": 0, "Dienstag": 0, "Mittwoch": 0, "Donnerstag": 0, "Freitag": 0, "Samstag": 1, "Sonntag": 1})

# Hinzufügen einer zusätzlichen Spalte mit den Jahreszeiten Frühling Sommer Herbst und Winter (FSHW) in Abhängigkeit des Datums
dataf["Jahreszeit_FSHW"] = dataf["Datum"].dt.month
dataf["Jahreszeit_FSHW"] = dataf["Datum"].dt.month.map({1: 4, 2: 4, 3: 1, 4: 1, 5: 1, 6: 2, 7: 2, 8: 2, 9: 3, 10: 3, 11: 3, 12: 4})

# Ausgabe der ersten 5 Zeilen des gemergten DataFrames
print(dataf.head())

# HISTOGRAMME
# Umsatz
plt.hist(dataf['Temperatur'].dropna(), bins=30)
# Hinzufügen von Titeln und Labels
plt.title('Histogramm Temperatur')
plt.xlabel('Temperatur')
plt.ylabel('Häufigkeit')
plt.show()

# Umsatz
plt.hist(dataf['Umsatz'].dropna(), bins=30)
# Hinzufügen von Titeln und Labels
plt.title('Histogramm Umsatz')
plt.xlabel('Umsatz')
plt.ylabel('Häufigkeit')
plt.show()

#Daten sehen linksschief verteilt aus. Umsatz soll geschätzt werden. Grundannahme von linearen Modellen liegt nicht vor. Daten müssen evtl. transformiert werden.
#siehe Shapiro-Wilk-Test

# Warengruppe
plt.hist(dataf['Warengruppe'].dropna(), bins=30)
# Hinzufügen von Titeln und Labels
plt.title('Histogramm Warengruppe')
plt.xlabel('Warengruppe')
plt.ylabel('Häufigkeit')
plt.show()

# Windgeschwindigkeit
plt.hist(dataf['Windgeschwindigkeit'].dropna(), bins=30)
# Hinzufügen von Titeln und Labels
plt.title('Histogramm Windgeschwindigkeit')
plt.xlabel('Windgeschwindigkeit')
plt.ylabel('Häufigkeit')
plt.show()

# Wettercode
plt.hist(dataf['Wettercode'].dropna(), bins=30)
# Hinzufügen von Titeln und Labels
plt.title('Histogramm Wettercode')
plt.xlabel('Wettercode')
plt.ylabel('Häufigkeit')
plt.show()


# SHAPIRO-WILK-TEST UMSATZ

# Shapiro-Wilk Test für die Variable 'umsatz'
stat, p_value = stats.shapiro(dataf['Umsatz'])

print("Shapiro-Wilk Teststatistik:", stat)
print("p-Wert:", p_value)

if p_value > 0.05:
    print("Die Nullhypothese kann nicht abgelehnt werden. Die Daten sind normalverteilt.")
else:
    print("Die Nullhypothese wird abgelehnt. Die Daten sind nicht normalverteilt.")

# Transformieren der Variablen
dataf['logUmsatz'] = np.log(dataf['Umsatz'].replace(0, np.nan))
dataf['asUmsatz'] = np.arcsin(dataf['Umsatz'].replace(0, np.nan) /dataf['Umsatz'].replace(0, np.nan).max())

# Ausgabe der ersten 5 Zeilen des gemergten DataFrames
print(dataf.head())

#Anzeigen der ersten Zeilen des DataFrame
print(dataf.head())

# Anzeigen der Beschreibung des DataFrame
print(dataf.describe())

# Histogramme für die transformierten Variablen

# asUmsatz
plt.hist(dataf['asUmsatz'].dropna(), bins=30)
# Hinzufügen von Titeln und Labels
plt.title('Histogramm ArcSin-Transformierter Umsatz')
plt.xlabel('ArcSin Umsatz')
plt.ylabel('Häufigkeit')
plt.show()

# logUmsatz
plt.hist(dataf['logUmsatz'].dropna(), bins=30)
# Hinzufügen von Titeln und Labels
plt.title('Histogramm Logarithmisch-Transformierter Umsatz')
plt.xlabel('Log(Umsatz)')
plt.ylabel('Häufigkeit')
plt.show()

# Shapiro-Wilk Test für die Variable 'logUmsatz'
stat, p_value = stats.shapiro(dataf['logUmsatz'])

print("Shapiro-Wilk Teststatistik:", stat)
print("p-Wert:", p_value)

if p_value > 0.05:
    print("Die Nullhypothese kann nicht abgelehnt werden. Die Daten sind normalverteilt.")
else:
    print("Die Nullhypothese wird abgelehnt. Die Daten sind nicht normalverteilt.")

# Shapiro-Wilk Test für die Variable asUmsatz'
stat, p_value = stats.shapiro(dataf['asUmsatz'])

print("Shapiro-Wilk Teststatistik:", stat)
print("p-Wert:", p_value)

if p_value > 0.05:
    print("Die Nullhypothese kann nicht abgelehnt werden. Die Daten sind normalverteilt.")
else:
    print("Die Nullhypothese wird abgelehnt. Die Daten sind nicht normalverteilt.")

# Daten sind auch nach Transformation nicht normalverteilt. Es wird weiter mit der Ursprungsvariable gearbeitet. 

# SCATTERPLOTS
#Temperatur vs.Umsatz
plt.figure(figsize=(8, 6))
plt.scatter(dataf['Temperatur'], dataf['Umsatz'], label='Daten')
plt.xlabel('Temperatur')
plt.ylabel('Umsatz')
plt.title('Scatterplot Temperatur vs Umsatz')
plt.show()

dataf = pd.DataFrame(dataf)

# Finde Spalten mit String-Werten
for col in dataf.columns:
    if dataf[col].apply(lambda x: isinstance(x, str)).any():
        print(f"Spalte '{col}' enthält String-Werte.")

#KORRELATIONSMATRIX

# Nicht-numerische und transformierte Spalten aus dem DataFrame entfernen
drop_df = dataf.drop(['Wochentag', 'logUmsatz','asUmsatz', 'Beschreibung', 'Uhrzeit_x', 'Heim_Auswärts_x', 'Uhrzeit_y', 'Heim_Auswärts_y'], axis=1)

# Korrelationsmatrix berechnen
corr_matrix = drop_df.corr()

# Korrelationsmatrix plotten
plt.figure(figsize=(10, 8))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)
plt.title('Korrelationsmatrix')
plt.show()