{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcixbGdQH6YZ"
      },
      "source": [
        "### Import Libraries and Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VPqpxN_gH6Yc",
        "outputId": "1b1b105e-0f9d-47dd-8da1-9abe5ec018ed"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Usecols do not match columns, columns expected but not found: ['Verbraucherpreisindex']",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m/workspaces/bakery_prediction/3_Model/Bjoerns_NN-Vorschlag/Bjoern_neural_net_data_preparation.ipynb Zelle 2\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bmusical-guacamole-976gp9rgw967hp955/workspaces/bakery_prediction/3_Model/Bjoerns_NN-Vorschlag/Bjoern_neural_net_data_preparation.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bmusical-guacamole-976gp9rgw967hp955/workspaces/bakery_prediction/3_Model/Bjoerns_NN-Vorschlag/Bjoern_neural_net_data_preparation.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Import Data\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://codespaces%2Bmusical-guacamole-976gp9rgw967hp955/workspaces/bakery_prediction/3_Model/Bjoerns_NN-Vorschlag/Bjoern_neural_net_data_preparation.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39m/workspaces/bakery_prediction/3_Model/Bjoerns_NN-Vorschlag/no_missing_data_gesamt.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m, usecols\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mDatum\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mWarengruppe\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mTemperatur\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mWochentag_MDMDFSS\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mVerbraucherpreisindex\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mFerienSH\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mFeiertag\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mJahreszeit_FSHW\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mWochenende\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mWindgeschwindigkeit\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mWettercode\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bmusical-guacamole-976gp9rgw967hp955/workspaces/bakery_prediction/3_Model/Bjoerns_NN-Vorschlag/Bjoern_neural_net_data_preparation.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m data[\u001b[39m'\u001b[39m\u001b[39mTemperatur_Cluster\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m  \u001b[39m# Alle Werte auf 0 setzen\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bmusical-guacamole-976gp9rgw967hp955/workspaces/bakery_prediction/3_Model/Bjoerns_NN-Vorschlag/Bjoern_neural_net_data_preparation.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# Setzen Sie die Werte in 'Temperatur_Cluster' basierend auf den Werten in 'Temperatur'\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1898\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1895\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1897\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1898\u001b[0m     \u001b[39mreturn\u001b[39;00m mapping[engine](f, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions)\n\u001b[1;32m   1899\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m   1900\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:140\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39morig_names \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39musecols_dtype \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mstring\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mset\u001b[39m(usecols)\u001b[39m.\u001b[39missubset(\n\u001b[1;32m    138\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39morig_names\n\u001b[1;32m    139\u001b[0m ):\n\u001b[0;32m--> 140\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_usecols_names(usecols, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49morig_names)\n\u001b[1;32m    142\u001b[0m \u001b[39m# error: Cannot determine type of 'names'\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnames) \u001b[39m>\u001b[39m \u001b[39mlen\u001b[39m(usecols):  \u001b[39m# type: ignore[has-type]\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     \u001b[39m# error: Cannot determine type of 'names'\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/base_parser.py:979\u001b[0m, in \u001b[0;36mParserBase._validate_usecols_names\u001b[0;34m(self, usecols, names)\u001b[0m\n\u001b[1;32m    977\u001b[0m missing \u001b[39m=\u001b[39m [c \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m usecols \u001b[39mif\u001b[39;00m c \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m names]\n\u001b[1;32m    978\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(missing) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 979\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    980\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUsecols do not match columns, columns expected but not found: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    981\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmissing\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    982\u001b[0m     )\n\u001b[1;32m    984\u001b[0m \u001b[39mreturn\u001b[39;00m usecols\n",
            "\u001b[0;31mValueError\u001b[0m: Usecols do not match columns, columns expected but not found: ['Verbraucherpreisindex']"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Import Data\n",
        "data = pd.read_csv(\"/workspaces/bakery_prediction/3_Model/Bjoerns_NN-Vorschlag/no_missing_data_gesamt.csv\", usecols=['Datum', 'Warengruppe', 'Temperatur', 'Wochentag_MDMDFSS', 'Verbraucherpreisindex', 'FerienSH', 'Feiertag', 'Jahreszeit_FSHW', 'Wochenende', 'Windgeschwindigkeit', 'Wettercode'])\n",
        "\n",
        "\n",
        "data['Temperatur_Cluster'] = 0  # Alle Werte auf 0 setzen\n",
        "\n",
        "# Setzen Sie die Werte in 'Temperatur_Cluster' basierend auf den Werten in 'Temperatur'\n",
        "data['Temperatur_Cluster'] = data['Temperatur'].apply(lambda x: 1 if x < 10 else (2 if x < 20 else 3))\n",
        "\n",
        "# Konvertieren Sie die 'Datum'-Spalte in ein Datumsformat\n",
        "data['Datum'] = pd.to_datetime(data['Datum'])\n",
        "\n",
        "data['Jahreszeit'] = 0  # Alle Werte auf 0 setzen\n",
        "\n",
        "# Setzen Sie die Werte in 'Jahreszeit' auf 1, wenn das Datum von Dezember bis Februar liegt\n",
        "data['Jahreszeit'] = data['Datum'].apply(lambda x: 4 if x.month in [12, 1, 2] else 1 if x.month in [3, 4, 5] else 2 if x.month in [6, 7, 8] else 3)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUWjuQjFH6Yd"
      },
      "source": [
        "### Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7UlKuUmTH6Ye",
        "outputId": "f36d296e-50e6-4144-ba7a-12fddcd47125"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warengruppe           int64\n",
            "Temperatur_Cluster    int64\n",
            "Jahreszeit            int64\n",
            "dtype: object\n",
            "Unique Values:\n",
            " Warengruppe           [1, 2, 3, 4, 5, 6, 0]\n",
            "Temperatur_Cluster                [2, 3, 1]\n",
            "Jahreszeit                     [2, 3, 4, 1]\n",
            "dtype: object\n",
            "(9372, 16)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Umsatz</th>\n",
              "      <th>Warengruppe_1</th>\n",
              "      <th>Warengruppe_2</th>\n",
              "      <th>Warengruppe_3</th>\n",
              "      <th>Warengruppe_4</th>\n",
              "      <th>Warengruppe_5</th>\n",
              "      <th>Warengruppe_6</th>\n",
              "      <th>Temperatur_Cluster_2</th>\n",
              "      <th>Temperatur_Cluster_3</th>\n",
              "      <th>Jahreszeit_2</th>\n",
              "      <th>Jahreszeit_3</th>\n",
              "      <th>Jahreszeit_4</th>\n",
              "      <th>FerienSH</th>\n",
              "      <th>Feiertag</th>\n",
              "      <th>Weihnachtsmarkt</th>\n",
              "      <th>Wochenende</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>148.828353</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>535.856285</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>201.198426</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>65.890169</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>317.475875</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Umsatz  Warengruppe_1  Warengruppe_2  Warengruppe_3  Warengruppe_4  \\\n",
              "0  148.828353              1              0              0              0   \n",
              "1  535.856285              0              1              0              0   \n",
              "2  201.198426              0              0              1              0   \n",
              "3   65.890169              0              0              0              1   \n",
              "4  317.475875              0              0              0              0   \n",
              "\n",
              "   Warengruppe_5  Warengruppe_6  Temperatur_Cluster_2  Temperatur_Cluster_3  \\\n",
              "0              0              0                     1                     0   \n",
              "1              0              0                     1                     0   \n",
              "2              0              0                     1                     0   \n",
              "3              0              0                     1                     0   \n",
              "4              1              0                     1                     0   \n",
              "\n",
              "   Jahreszeit_2  Jahreszeit_3  Jahreszeit_4  FerienSH  Feiertag  \\\n",
              "0             1             0             0         1         0   \n",
              "1             1             0             0         1         0   \n",
              "2             1             0             0         1         0   \n",
              "3             1             0             0         1         0   \n",
              "4             1             0             0         1         0   \n",
              "\n",
              "   Weihnachtsmarkt  Wochenende  \n",
              "0                0           0  \n",
              "1                0           0  \n",
              "2                0           0  \n",
              "3                0           0  \n",
              "4                0           0  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define categorical features\n",
        "categorical_features = ['Warengruppe', 'Temperatur_Cluster', 'Jahreszeit']\n",
        "\n",
        "# Inspect data types and unique values for categorical columns\n",
        "print(data[categorical_features].dtypes)\n",
        "print(\"Unique Values:\\n\",data[categorical_features].apply(lambda x: x.unique()))\n",
        "\n",
        "# Ensure categorical columns are treated as categories\n",
        "for col in categorical_features:\n",
        "    data[col] = data[col].astype('category')\n",
        "\n",
        "# Encode categorical variables using pd.get_dummies\n",
        "features = pd.get_dummies(data[categorical_features], drop_first=True, dtype=int)\n",
        "\n",
        "# Include any numeric columns that are not categorical\n",
        "numerical_features = data[['FerienSH', 'Feiertag', 'Weihnachtsmarkt', 'Wochenende']] \n",
        "\n",
        "# Construct the prepared data set including the dependent variable ('label')\n",
        "prepared_data = pd.concat([data[['Umsatz']], features, numerical_features], axis=1).dropna()\n",
        "\n",
        "# Handle missing values by removing rows with any missing values\n",
        "prepared_data = prepared_data.dropna()\n",
        "\n",
        "# Display the shape of the prepared data set\n",
        "print(prepared_data.shape)\n",
        "# Display the first few rows of the prepared data set\n",
        "prepared_data.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToWs4RU9H6Ye"
      },
      "source": [
        "### Selection of Training and Validation Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9eIQ_keGH6Ye",
        "outputId": "593e8cc3-e9fe-4ea5-88c2-406b7355198d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training features dimensions: (7497, 15)\n",
            "Validation features dimensions: (1874, 15)\n",
            "\n",
            "Training labels dimensions: (7497, 1)\n",
            "Validation labels dimensions: (1874, 1)\n"
          ]
        }
      ],
      "source": [
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Shuffle the data\n",
        "prepared_data = prepared_data.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# Calculate the number of rows for each dataset\n",
        "n_total = len(prepared_data)\n",
        "# n_training = int(0.7 * n_total)\n",
        "n_training = int(0.8 * n_total)\n",
        "n_validation = int(0.20 * n_total)\n",
        "\n",
        "# Split the features and labels for training, validation, and test\n",
        "training_data = prepared_data.iloc[:n_training]\n",
        "validation_data = prepared_data.iloc[n_training:n_training+n_validation]\n",
        "# test_data = prepared_data.iloc[n_training+n_validation:]\n",
        "\n",
        "# Separating features and labels\n",
        "training_features = training_data.drop('Umsatz', axis=1)\n",
        "validation_features = validation_data.drop('Umsatz', axis=1)\n",
        "# test_features = test_data.drop('Umsatz', axis=1)\n",
        "\n",
        "training_labels = training_data[['Umsatz']]\n",
        "validation_labels = validation_data[['Umsatz']]\n",
        "# test_labels = test_data[['Umsatz']]\n",
        "\n",
        "# Print dimensions of the dataframes\n",
        "print(\"Training features dimensions:\", training_features.shape)\n",
        "print(\"Validation features dimensions:\", validation_features.shape)\n",
        "# print(\"Test features dimensions:\", test_features.shape)\n",
        "print()\n",
        "print(\"Training labels dimensions:\", training_labels.shape)\n",
        "print(\"Validation labels dimensions:\", validation_labels.shape)\n",
        "# print(\"Test labels dimensions:\", test_labels.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9OqnXDRH6Yf"
      },
      "source": [
        "#### Data Export"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1AX0OVMcH6Yf"
      },
      "outputs": [],
      "source": [
        "# Create subdirectory for the pickle files\n",
        "subdirectory = \"pickle_data\"\n",
        "os.makedirs(subdirectory, exist_ok=True)\n",
        "\n",
        "# Export of the prepared data to subdirectory as pickle files\n",
        "training_features.to_pickle(f\"{subdirectory}/training_features.pkl\")\n",
        "validation_features.to_pickle(f\"{subdirectory}/validation_features.pkl\")\n",
        "# test_features.to_pickle(f\"{subdirectory}/test_features.pkl\")\n",
        "training_labels.to_pickle(f\"{subdirectory}/training_labels.pkl\")\n",
        "validation_labels.to_pickle(f\"{subdirectory}/validation_labels.pkl\")\n",
        "# test_labels.to_pickle(f\"{subdirectory}/test_labels.pkl\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
