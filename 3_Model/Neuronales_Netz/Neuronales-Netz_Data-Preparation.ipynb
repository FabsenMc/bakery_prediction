{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation für das Neuronale Netz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importieren der Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importieren des Datensatzes sowie Aufteilung der Umsätze in eine Spalte pro Warengruppe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datum                   datetime64[ns]\n",
      "KielerWoche                    float64\n",
      "Warengruppe                    float64\n",
      "Umsatz                         float64\n",
      "Bewoelkung                     float64\n",
      "Temperatur                     float64\n",
      "Windgeschwindigkeit            float64\n",
      "Wettercode                     float64\n",
      "Beschreibung                    object\n",
      "FerienSH                       float64\n",
      "Feiertag                       float64\n",
      "Uhrzeit                         object\n",
      "Heim_Auswärts                   object\n",
      "Umschlag                       float64\n",
      "Weihnachtsmarkt                float64\n",
      "Regen                            int64\n",
      "Wochentag_MDMDFSS                int64\n",
      "Wochenende                       int64\n",
      "Jahreszeit_FSHW                  int64\n",
      "Temperatur_Kategorie            object\n",
      "dtype: object\n",
      "       Datum  Warengruppe_1.0  Warengruppe_2.0  Warengruppe_3.0  \\\n",
      "0 2013-07-01       148.828353       535.856285       201.198426   \n",
      "1 2013-07-02       159.793757       546.780787       265.261254   \n",
      "2 2013-07-03       111.885594       427.343259       210.260241   \n",
      "3 2013-07-04       168.864941       454.859641       190.686641   \n",
      "4 2013-07-05       171.280754       492.818804       181.644870   \n",
      "\n",
      "   Warengruppe_4.0  Warengruppe_5.0  Warengruppe_6.0  \n",
      "0        65.890169       317.475875              0.0  \n",
      "1        74.543917       383.628682              0.0  \n",
      "2        69.262728       305.523072              0.0  \n",
      "3        61.490175       308.408168              0.0  \n",
      "4        86.759861       355.518770              0.0  \n",
      "Datum              datetime64[ns]\n",
      "Warengruppe_1.0           float64\n",
      "Warengruppe_2.0           float64\n",
      "Warengruppe_3.0           float64\n",
      "Warengruppe_4.0           float64\n",
      "Warengruppe_5.0           float64\n",
      "Warengruppe_6.0           float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Laden des Datensatzes\n",
    "dataf = pd.read_csv(\"https://raw.githubusercontent.com/FabsenMc/bakery_prediction/main/0_DataPreparation/dataf.csv\")\n",
    "\n",
    "# Convert the date column to datetime (sicherheitshalber)\n",
    "dataf['Datum'] = pd.to_datetime(dataf['Datum'])\n",
    "\n",
    "# prüfen welche Spalten in Categories umgewandelt werden müssen\n",
    "print(dataf.dtypes)\n",
    "\n",
    "# Pivot the data to have one row per date and one column per category\n",
    "pivot_dataf = dataf.pivot_table(index='Datum', columns='Warengruppe', values='Umsatz').reset_index()\n",
    "\n",
    "#New created columns get the prefix 'Warengruppe_'\n",
    "pivot_dataf.columns = ['Datum'] + ['Warengruppe_' + str(col) for col in pivot_dataf.columns if col != 'Datum']\n",
    "\n",
    "# Ensure no missing values by filling them with zeros (hier vmtl wichtig für Warengruppe 6)\n",
    "pivot_dataf.fillna(0, inplace=True)\n",
    "\n",
    "# Change the type of all columns with the prefix 'Warengruppe_' to float\n",
    "for col in pivot_dataf.columns:\n",
    "    if 'Warengruppe_' in col:\n",
    "        pivot_dataf[col] = pivot_dataf[col].astype(float)\n",
    "\n",
    "# Anzeigen lassen ob die Pivotierung funktioniert hat und wie die Spalten heißen\n",
    "print(pivot_dataf.head())\n",
    "print(pivot_dataf.dtypes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kategorielle Variablen definieren und mit dem restlichen Datensatz vereinigen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Values:\n",
      " Temperatur_Kategorie                         [Niedrig, nan, Mittel, Hoch]\n",
      "Bewoelkung              [8.0, 7.0, 4.0, 6.0, 3.0, 2.0, 1.0, 5.0, 0.0, ...\n",
      "Jahreszeit_FSHW                                              [4, 1, 2, 3]\n",
      "Wochenende                                                         [1, 0]\n",
      "dtype: object\n",
      "Prepared data shape:\n",
      " (1819, 21)\n",
      "Prepared data first rows:\n",
      "        Datum  Warengruppe_1.0  Warengruppe_2.0  Warengruppe_3.0  \\\n",
      "0 2013-07-01       148.828353       535.856285       201.198426   \n",
      "1 2013-07-02       159.793757       546.780787       265.261254   \n",
      "2 2013-07-03       111.885594       427.343259       210.260241   \n",
      "3 2013-07-04       168.864941       454.859641       190.686641   \n",
      "4 2013-07-05       171.280754       492.818804       181.644870   \n",
      "\n",
      "   Warengruppe_4.0  Warengruppe_5.0  Warengruppe_6.0  \\\n",
      "0        65.890169       317.475875              0.0   \n",
      "1        74.543917       383.628682              0.0   \n",
      "2        69.262728       305.523072              0.0   \n",
      "3        61.490175       308.408168              0.0   \n",
      "4        86.759861       355.518770              0.0   \n",
      "\n",
      "   Temperatur_Kategorie_Mittel  Temperatur_Kategorie_Niedrig  Bewoelkung_1.0  \\\n",
      "0                            0                             1               0   \n",
      "1                            0                             1               0   \n",
      "2                            0                             1               0   \n",
      "3                            0                             1               0   \n",
      "4                            0                             1               0   \n",
      "\n",
      "   ...  Bewoelkung_3.0  Bewoelkung_4.0  Bewoelkung_5.0  Bewoelkung_6.0  \\\n",
      "0  ...               0               0               0               0   \n",
      "1  ...               0               0               0               0   \n",
      "2  ...               0               0               0               0   \n",
      "3  ...               0               1               0               0   \n",
      "4  ...               0               0               0               1   \n",
      "\n",
      "   Bewoelkung_7.0  Bewoelkung_8.0  Jahreszeit_FSHW_2  Jahreszeit_FSHW_3  \\\n",
      "0               0               1                  0                  0   \n",
      "1               1               0                  0                  0   \n",
      "2               0               1                  0                  0   \n",
      "3               0               0                  0                  0   \n",
      "4               0               0                  0                  0   \n",
      "\n",
      "   Jahreszeit_FSHW_4  Wochenende_1  \n",
      "0                  1             1  \n",
      "1                  1             0  \n",
      "2                  1             0  \n",
      "3                  1             0  \n",
      "4                  1             0  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "Feature Columns:\n",
      " Index(['Temperatur_Kategorie_Mittel', 'Temperatur_Kategorie_Niedrig',\n",
      "       'Bewoelkung_1.0', 'Bewoelkung_2.0', 'Bewoelkung_3.0', 'Bewoelkung_4.0',\n",
      "       'Bewoelkung_5.0', 'Bewoelkung_6.0', 'Bewoelkung_7.0', 'Bewoelkung_8.0',\n",
      "       'Jahreszeit_FSHW_2', 'Jahreszeit_FSHW_3', 'Jahreszeit_FSHW_4',\n",
      "       'Wochenende_1'],\n",
      "      dtype='object')\n",
      "Target Columns:\n",
      " Index(['Warengruppe_1.0', 'Warengruppe_2.0', 'Warengruppe_3.0',\n",
      "       'Warengruppe_4.0', 'Warengruppe_5.0', 'Warengruppe_6.0'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Features aus dem Datensatz herausziehen (hier nur beispielhaft, muss erweitert werden), die ins neuronale Netz eingehen sollen (es scheinen alle am Ende Kategorial zu sein bei uns)\n",
    "categorical_features = ['Temperatur_Kategorie', 'Bewoelkung', \"Jahreszeit_FSHW\", \"Wochenende\"] \n",
    "\n",
    "# Überprüfen der einzigartigen Werte in den kategorialen Features und umwandlung in Type category falls es nicht schon vorher so war\n",
    "print(\"Unique Values:\\n\",dataf[categorical_features].apply(lambda x: x.unique()))\n",
    "for col in categorical_features:\n",
    "    dataf[col] = dataf[col].astype('category')\n",
    "\n",
    "# Die gewählten Features hier in dummies codieren\n",
    "features = pd.get_dummies(dataf[categorical_features], drop_first=True, dtype=int)\n",
    "\n",
    "# Dependend Varibale (Bei uns der Umsatz pro Warengruppe) mit den Features zusammenfügen\n",
    "prepared_data = pd.concat([pivot_dataf, features], axis=1)\n",
    "\n",
    "# missing values werden entfernt\n",
    "prepared_data = prepared_data.dropna()\n",
    "\n",
    "#DF nach Datum sortieren\n",
    "prepared_data = prepared_data.sort_values(by='Datum')\n",
    "\n",
    "# Display the shape of the prepared data set\n",
    "print(\"Prepared data shape:\\n\", prepared_data.shape)\n",
    "# Display the first few rows of the prepared data set\n",
    "print(\"Prepared data first rows:\\n\", prepared_data.head())\n",
    "\n",
    "# Define the feature columns and target columns\n",
    "feature_columns = prepared_data.columns[prepared_data.columns.str.startswith('Temperatur_Kategorie') | prepared_data.columns.str.startswith('Bewoelkung') | prepared_data.columns.str.startswith('Jahreszeit_FSHW') | prepared_data.columns.str.startswith('Wochenende')]\n",
    "target_columns = prepared_data.columns[prepared_data.columns.str.startswith('Warengruppe_')]\n",
    "\n",
    "print(\"Feature Columns:\\n\", feature_columns)\n",
    "print(\"Target Columns:\\n\", target_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split des Datensatzes in Trainings und Validierungsdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Datum  Warengruppe_1.0  Warengruppe_2.0  Warengruppe_3.0  \\\n",
      "0 2015-12-24       195.399801       395.242017       137.024358   \n",
      "1 2016-08-01       161.443574       612.243855       315.867117   \n",
      "2 2014-08-27       141.124541       552.631235       203.476569   \n",
      "3 2014-12-14       102.805573       588.469539       199.263308   \n",
      "4 2016-05-21       134.348752       417.308631       175.636694   \n",
      "\n",
      "   Warengruppe_4.0  Warengruppe_5.0  Warengruppe_6.0  \\\n",
      "0       118.865410       275.561445        69.400013   \n",
      "1        76.277148       334.375656         0.000000   \n",
      "2        91.759601       357.732101         0.000000   \n",
      "3       106.105028       310.473798       119.152733   \n",
      "4        96.085798       255.045369         0.000000   \n",
      "\n",
      "   Temperatur_Kategorie_Mittel  Temperatur_Kategorie_Niedrig  Bewoelkung_1.0  \\\n",
      "0                            1                             0               0   \n",
      "1                            1                             0               0   \n",
      "2                            0                             0               0   \n",
      "3                            0                             0               0   \n",
      "4                            1                             0               0   \n",
      "\n",
      "   ...  Bewoelkung_3.0  Bewoelkung_4.0  Bewoelkung_5.0  Bewoelkung_6.0  \\\n",
      "0  ...               0               0               0               0   \n",
      "1  ...               0               0               0               0   \n",
      "2  ...               0               0               0               0   \n",
      "3  ...               0               0               0               0   \n",
      "4  ...               0               0               0               1   \n",
      "\n",
      "   Bewoelkung_7.0  Bewoelkung_8.0  Jahreszeit_FSHW_2  Jahreszeit_FSHW_3  \\\n",
      "0               0               1                  0                  1   \n",
      "1               0               0                  0                  1   \n",
      "2               0               0                  0                  0   \n",
      "3               0               0                  1                  0   \n",
      "4               0               0                  0                  1   \n",
      "\n",
      "   Jahreszeit_FSHW_4  Wochenende_1  \n",
      "0                  0             0  \n",
      "1                  0             0  \n",
      "2                  1             1  \n",
      "3                  0             0  \n",
      "4                  0             0  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "       Datum  Warengruppe_1.0  Warengruppe_2.0  Warengruppe_3.0  \\\n",
      "0 2018-02-04        53.013800       379.119370       148.452873   \n",
      "1 2017-09-26       151.541843       340.433148       114.213523   \n",
      "2 2017-10-27       176.844444       362.446375       158.940547   \n",
      "3 2018-06-01       171.352211       391.076359       196.047936   \n",
      "4 2018-07-12       207.879340       528.582312       225.776865   \n",
      "\n",
      "   Warengruppe_4.0  Warengruppe_5.0  Warengruppe_6.0  \\\n",
      "0       100.246292       328.403879              0.0   \n",
      "1        94.681895       251.236254              0.0   \n",
      "2        84.972901       270.124179              0.0   \n",
      "3        72.554840       299.632066              0.0   \n",
      "4       118.081150       284.685670              0.0   \n",
      "\n",
      "   Temperatur_Kategorie_Mittel  Temperatur_Kategorie_Niedrig  Bewoelkung_1.0  \\\n",
      "0                            0                             1               0   \n",
      "1                            0                             1               0   \n",
      "2                            0                             1               0   \n",
      "3                            0                             1               0   \n",
      "4                            0                             1               0   \n",
      "\n",
      "   ...  Bewoelkung_3.0  Bewoelkung_4.0  Bewoelkung_5.0  Bewoelkung_6.0  \\\n",
      "0  ...               0               0               0               0   \n",
      "1  ...               0               0               1               0   \n",
      "2  ...               0               0               0               0   \n",
      "3  ...               0               0               0               0   \n",
      "4  ...               0               0               0               0   \n",
      "\n",
      "   Bewoelkung_7.0  Bewoelkung_8.0  Jahreszeit_FSHW_2  Jahreszeit_FSHW_3  \\\n",
      "0               1               0                  0                  0   \n",
      "1               0               0                  0                  0   \n",
      "2               1               0                  0                  0   \n",
      "3               1               0                  0                  0   \n",
      "4               0               0                  0                  0   \n",
      "\n",
      "   Jahreszeit_FSHW_4  Wochenende_1  \n",
      "0                  1             0  \n",
      "1                  1             1  \n",
      "2                  1             0  \n",
      "3                  1             0  \n",
      "4                  0             1  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "Training dataset dimensions: (1462, 21)\n",
      "Validation dataset dimensions: (357, 21)\n",
      "Training features dimensions: (1462, 14)\n",
      "Validation features dimensions: (357, 14)\n",
      "\n",
      "Training labels dimensions: (1462, 6)\n",
      "Validation labels dimensions: (357, 6)\n"
     ]
    }
   ],
   "source": [
    "# Hier muss vermutlich nochmnal eine Randomisierung rein (durchmischen damit nicht zufällig in einem Batch zusammenhängende Daten landen)\n",
    "# vermutlich nach dem auftrennen der Datensätze in die zwei Gruppen (da geht Datum eh verloren)\n",
    "\n",
    "\n",
    "# Definieren der Datumsgrenzen\n",
    "train_start_date = '2013-07-01'\n",
    "train_end_date = '2017-07-31'\n",
    "validation_end_date = '2018-07-31'\n",
    "\n",
    "# Split the data into training (3 years) and validation (1 year)\n",
    "train_data = prepared_data[(prepared_data['Datum']>= train_start_date) & (prepared_data['Datum'] <= train_end_date)]\n",
    "val_data = prepared_data[(prepared_data['Datum']> train_end_date) & (prepared_data['Datum'] <= validation_end_date)]\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Shuffle the data -> mischt die Daten vmtl durch falls sie vorher sortiert waren und löscht den Index falls es einen gab\n",
    "train_data = train_data.sample(frac=1).reset_index(drop=True)\n",
    "val_data = val_data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "print(train_data.head())\n",
    "print(val_data.head())\n",
    "\n",
    "# Überprüfen der Dimensionen der Datensätze\n",
    "print(\"Training dataset dimensions:\", train_data.shape)\n",
    "print(\"Validation dataset dimensions:\", val_data.shape)\n",
    "\n",
    "# Separating features and labels/targets\n",
    "training_features = pd.DataFrame(train_data[feature_columns].values)\n",
    "validation_features = pd.DataFrame(val_data[feature_columns].values)\n",
    "\n",
    "training_labels = pd.DataFrame(train_data[target_columns].values)\n",
    "validation_labels = pd.DataFrame(val_data[target_columns].values)\n",
    "\n",
    "# Print dimensions of the features and labels\n",
    "print(\"Training features dimensions:\", training_features.shape)\n",
    "print(\"Validation features dimensions:\", validation_features.shape)\n",
    "print()\n",
    "print(\"Training labels dimensions:\", training_labels.shape)\n",
    "print(\"Validation labels dimensions:\", validation_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subdirectory for the pickle files -> dadurch behalten die Daten ihre Types\n",
    "subdirectory = \"pickle_data\"\n",
    "os.makedirs(subdirectory, exist_ok=True)\n",
    "\n",
    "# Export of the prepared data to subdirectory as pickle files\n",
    "training_features.to_pickle(f\"{subdirectory}/training_features.pkl\")\n",
    "validation_features.to_pickle(f\"{subdirectory}/validation_features.pkl\")\n",
    "training_labels.to_pickle(f\"{subdirectory}/training_labels.pkl\")\n",
    "validation_labels.to_pickle(f\"{subdirectory}/validation_labels.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
