{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Datum  Warengruppe_1.0  Warengruppe_2.0  Warengruppe_3.0  \\\n",
      "0 2013-07-01       148.828353       535.856285       201.198426   \n",
      "1 2013-07-02       159.793757       546.780787       265.261254   \n",
      "2 2013-07-03       111.885594       427.343259       210.260241   \n",
      "3 2013-07-04       168.864941       454.859641       190.686641   \n",
      "4 2013-07-05       171.280754       492.818804       181.644870   \n",
      "\n",
      "   Warengruppe_4.0  Warengruppe_5.0  Warengruppe_6.0  \n",
      "0        65.890169       317.475875              NaN  \n",
      "1        74.543917       383.628682              NaN  \n",
      "2        69.262728       305.523072              NaN  \n",
      "3        61.490175       308.408168              NaN  \n",
      "4        86.759861       355.518770              NaN  \n",
      "       Datum  Warengruppe_1.0  Warengruppe_2.0  Warengruppe_3.0  \\\n",
      "0 2013-07-01       148.828353       535.856285       201.198426   \n",
      "1 2013-07-02       159.793757       546.780787       265.261254   \n",
      "2 2013-07-03       111.885594       427.343259       210.260241   \n",
      "3 2013-07-04       168.864941       454.859641       190.686641   \n",
      "4 2013-07-05       171.280754       492.818804       181.644870   \n",
      "\n",
      "   Warengruppe_4.0  Warengruppe_5.0  Warengruppe_6.0 Temperatur_Kategorie  \\\n",
      "0        65.890169       317.475875              NaN               Mittel   \n",
      "1        74.543917       383.628682              NaN               Mittel   \n",
      "2        69.262728       305.523072              NaN                 Hoch   \n",
      "3        61.490175       308.408168              NaN               Mittel   \n",
      "4        86.759861       355.518770              NaN               Mittel   \n",
      "\n",
      "   Bewoelkung  \n",
      "0         6.0  \n",
      "1         3.0  \n",
      "2         7.0  \n",
      "3         7.0  \n",
      "4         5.0  \n",
      "       Datum  Warengruppe_1.0  Warengruppe_2.0  Warengruppe_3.0  \\\n",
      "0 2013-07-01       148.828353       535.856285       201.198426   \n",
      "1 2013-07-02       159.793757       546.780787       265.261254   \n",
      "2 2013-07-03       111.885594       427.343259       210.260241   \n",
      "3 2013-07-04       168.864941       454.859641       190.686641   \n",
      "4 2013-07-05       171.280754       492.818804       181.644870   \n",
      "\n",
      "   Warengruppe_4.0  Warengruppe_5.0  Warengruppe_6.0 Temperatur_Kategorie  \\\n",
      "0        65.890169       317.475875              0.0               Mittel   \n",
      "1        74.543917       383.628682              0.0               Mittel   \n",
      "2        69.262728       305.523072              0.0                 Hoch   \n",
      "3        61.490175       308.408168              0.0               Mittel   \n",
      "4        86.759861       355.518770              0.0               Mittel   \n",
      "\n",
      "   Bewoelkung  \n",
      "0         6.0  \n",
      "1         3.0  \n",
      "2         7.0  \n",
      "3         7.0  \n",
      "4         5.0  \n",
      "Training dataset dimensions: (1819, 9)\n",
      "Validation dataset dimensions: (357, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18482/2563470082.py:37: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  train_data = pivot_dataf[(pivot_dataf['Datum']>= train_start_date) & (dataf['Datum'] <= train_end_date)]\n",
      "/tmp/ipykernel_18482/2563470082.py:38: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  val_data = pivot_dataf[(pivot_dataf['Datum']> train_end_date) & (dataf['Datum'] <= validation_end_date)]\n"
     ]
    }
   ],
   "source": [
    "# Assuming the new dataset is saved as 'bakery_sales.csv'\n",
    "# The dataset has columns: 'date', 'category', 'sales_volume', 'temperature', 'cloud_coverage'\n",
    "dataf = pd.read_csv(\"https://raw.githubusercontent.com/FabsenMc/bakery_prediction/main/0_DataPreparation/dataf.csv\")\n",
    "\n",
    "# Convert the date column to datetime\n",
    "dataf['Datum'] = pd.to_datetime(dataf['Datum'])\n",
    "\n",
    "# Pivot the data to have one row per date and one column per category\n",
    "pivot_dataf = dataf.pivot_table(index='Datum', columns='Warengruppe', values='Umsatz').reset_index()\n",
    "\n",
    "#New created columns get the prefix 'Warengruppe_'\n",
    "pivot_dataf.columns = ['Datum'] + ['Warengruppe_' + str(col) for col in pivot_dataf.columns if col != 'Datum']\n",
    "\n",
    "print(pivot_dataf.head())\n",
    "\n",
    "# Add temperature and cloud coverage columns to the pivoted data\n",
    "pivot_dataf = pivot_dataf.merge(dataf[['Datum', 'Temperatur_Kategorie', 'Bewoelkung']].drop_duplicates(), on='Datum')\n",
    "\n",
    "# Display the first few rows of the prepared data\n",
    "print(pivot_dataf.head())\n",
    "\n",
    "# Ensure no missing values by filling them with zeros\n",
    "pivot_dataf.fillna(0, inplace=True)\n",
    "\n",
    "print(pivot_dataf.head())\n",
    "\n",
    "# Define the feature columns and target columns\n",
    "feature_columns = ['Temperatur_Kategorie', 'Bewoelkung']\n",
    "target_columns = pivot_dataf.columns[pivot_dataf.columns.str.startswith('Warengruppe_')]\n",
    "\n",
    "# Definieren der Datumsgrenzen\n",
    "train_start_date = '2013-07-01'\n",
    "train_end_date = '2017-07-31'\n",
    "validation_end_date = '2018-07-31'\n",
    "\n",
    "# Split the data into training (3 years) and validation (1 year)\n",
    "train_data = pivot_dataf[(pivot_dataf['Datum']>= train_start_date) & (dataf['Datum'] <= train_end_date)]\n",
    "val_data = pivot_dataf[(pivot_dataf['Datum']> train_end_date) & (dataf['Datum'] <= validation_end_date)]\n",
    "\n",
    "# ÃœberprÃ¼fen der Dimensionen der DatensÃ¤tze\n",
    "print(\"Training dataset dimensions:\", train_data.shape)\n",
    "print(\"Validation dataset dimensions:\", val_data.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
