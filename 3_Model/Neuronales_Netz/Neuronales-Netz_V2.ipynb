{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation für das Neuronale Netz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importieren der Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importieren des Datensatzes sowie Aufteilung der Umsätze in eine Spalte pro Warengruppe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datum                   datetime64[ns]\n",
      "KielerWoche                    float64\n",
      "Warengruppe                    float64\n",
      "Umsatz                         float64\n",
      "Bewoelkung                     float64\n",
      "Temperatur                     float64\n",
      "Windgeschwindigkeit            float64\n",
      "Wettercode                     float64\n",
      "Beschreibung                    object\n",
      "FerienSH                       float64\n",
      "Feiertag                       float64\n",
      "Uhrzeit                         object\n",
      "Heim_Auswärts                   object\n",
      "Umschlag                       float64\n",
      "Weihnachtsmarkt                float64\n",
      "Regen                            int64\n",
      "Wochentag_MDMDFSS                int64\n",
      "Wochenende                       int64\n",
      "Jahreszeit_FSHW                  int64\n",
      "Temperatur_Kategorie            object\n",
      "dtype: object\n",
      "Datum              datetime64[ns]\n",
      "Warengruppe_1.0           float64\n",
      "Warengruppe_2.0           float64\n",
      "Warengruppe_3.0           float64\n",
      "Warengruppe_4.0           float64\n",
      "Warengruppe_5.0           float64\n",
      "Warengruppe_6.0           float64\n",
      "dtype: object\n",
      "       Datum  Warengruppe_1.0  Warengruppe_2.0  Warengruppe_3.0  \\\n",
      "0 2013-07-01       148.828353       535.856285       201.198426   \n",
      "1 2013-07-02       159.793757       546.780787       265.261254   \n",
      "2 2013-07-03       111.885594       427.343259       210.260241   \n",
      "3 2013-07-04       168.864941       454.859641       190.686641   \n",
      "4 2013-07-05       171.280754       492.818804       181.644870   \n",
      "\n",
      "   Warengruppe_4.0  Warengruppe_5.0  Warengruppe_6.0  \n",
      "0        65.890169       317.475875              0.0  \n",
      "1        74.543917       383.628682              0.0  \n",
      "2        69.262728       305.523072              0.0  \n",
      "3        61.490175       308.408168              0.0  \n",
      "4        86.759861       355.518770              0.0  \n"
     ]
    }
   ],
   "source": [
    "# Laden des Datensatzes\n",
    "dataf = pd.read_csv(\"https://raw.githubusercontent.com/FabsenMc/bakery_prediction/main/0_DataPreparation/dataf.csv\")\n",
    "\n",
    "# Convert the date column to datetime (sicherheitshalber)\n",
    "dataf['Datum'] = pd.to_datetime(dataf['Datum'])\n",
    "\n",
    "# prüfen welche Spalten in Categories umgewandelt werden müssen\n",
    "print(dataf.dtypes)\n",
    "\n",
    "# Pivot the data to have one row per date and one column per category\n",
    "pivot_dataf = dataf.pivot_table(index='Datum', columns='Warengruppe', values='Umsatz').reset_index()\n",
    "\n",
    "#New created columns get the prefix 'Warengruppe_'\n",
    "pivot_dataf.columns = ['Datum'] + ['Warengruppe_' + str(col) for col in pivot_dataf.columns if col != 'Datum']\n",
    "\n",
    "# Ensure no missing values by filling them with zeros (hier vmtl wichtig für Warengruppe 6)\n",
    "pivot_dataf.fillna(0, inplace=True)\n",
    "\n",
    "# Change the type of all columns with the prefix 'Warengruppe_' to float\n",
    "for col in pivot_dataf.columns:\n",
    "    if 'Warengruppe_' in col:\n",
    "        pivot_dataf[col] = pivot_dataf[col].astype(float)\n",
    "\n",
    "# Anzeigen lassen ob die Pivotierung funktioniert hat und wie die Spalten heißen\n",
    "print(pivot_dataf.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kategorielle Variablen definieren und mit dem restlichen Datensatz vereinigen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Values:\n",
      " Temperatur_Kategorie    ['Niedrig', NaN, 'Mittel', 'Hoch']\n",
      "Categories ...\n",
      "Bewoelkung              [8.0, 7.0, 4.0, 6.0, 3.0, 2.0, 1.0, 5.0, 0.0, ...\n",
      "dtype: object\n",
      "Prepared data shape:\n",
      " (1819, 17)\n",
      "Prepared data first rows:\n",
      "        Datum  Warengruppe_1.0  Warengruppe_2.0  Warengruppe_3.0  \\\n",
      "0 2013-07-01       148.828353       535.856285       201.198426   \n",
      "1 2013-07-02       159.793757       546.780787       265.261254   \n",
      "2 2013-07-03       111.885594       427.343259       210.260241   \n",
      "3 2013-07-04       168.864941       454.859641       190.686641   \n",
      "4 2013-07-05       171.280754       492.818804       181.644870   \n",
      "\n",
      "   Warengruppe_4.0  Warengruppe_5.0  Warengruppe_6.0  \\\n",
      "0        65.890169       317.475875              0.0   \n",
      "1        74.543917       383.628682              0.0   \n",
      "2        69.262728       305.523072              0.0   \n",
      "3        61.490175       308.408168              0.0   \n",
      "4        86.759861       355.518770              0.0   \n",
      "\n",
      "   Temperatur_Kategorie_Mittel  Temperatur_Kategorie_Niedrig  Bewoelkung_1.0  \\\n",
      "0                            0                             1               0   \n",
      "1                            0                             1               0   \n",
      "2                            0                             1               0   \n",
      "3                            0                             1               0   \n",
      "4                            0                             1               0   \n",
      "\n",
      "   Bewoelkung_2.0  Bewoelkung_3.0  Bewoelkung_4.0  Bewoelkung_5.0  \\\n",
      "0               0               0               0               0   \n",
      "1               0               0               0               0   \n",
      "2               0               0               0               0   \n",
      "3               0               0               1               0   \n",
      "4               0               0               0               0   \n",
      "\n",
      "   Bewoelkung_6.0  Bewoelkung_7.0  Bewoelkung_8.0  \n",
      "0               0               0               1  \n",
      "1               0               1               0  \n",
      "2               0               0               1  \n",
      "3               0               0               0  \n",
      "4               1               0               0  \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m feature_columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTemperatur_Kategorie\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBewoelkung\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     25\u001b[0m target_columns \u001b[38;5;241m=\u001b[39m pivot_dataf\u001b[38;5;241m.\u001b[39mcolumns[pivot_dataf\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWarengruppe_\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature Columns:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[43mfeature_columns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead\u001b[49m())\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget Columns:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, target_columns\u001b[38;5;241m.\u001b[39mhead())\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "# Features aus dem Datensatz herausziehen (hier nur beispielhaft, muss erweitert werden), die ins neuronale Netz eingehen sollen (es scheinen alle am Ende Kategorial zu sein bei uns)\n",
    "categorical_features = ['Temperatur_Kategorie', 'Bewoelkung']\n",
    "\n",
    "# Überprüfen der einzigartigen Werte in den kategorialen Features und umwandlung in Type category falls es nicht schon vorher so war\n",
    "print(\"Unique Values:\\n\",dataf[categorical_features].apply(lambda x: x.unique()))\n",
    "for col in categorical_features:\n",
    "    dataf[col] = dataf[col].astype('category')\n",
    "\n",
    "# Die gewählten Features hier in dummies codieren\n",
    "features = pd.get_dummies(dataf[categorical_features], drop_first=True, dtype=int)\n",
    "\n",
    "# Hier zieht man jetzt die dependend Varibale aus dem ursprünglichen Datensatz raus (Bei uns der Umsatz) und fügt sie mit den Features zusammen\n",
    "prepared_data = pd.concat([pivot_dataf, features], axis=1)\n",
    "\n",
    "# missing values werden entfernt\n",
    "prepared_data = prepared_data.dropna()\n",
    "\n",
    "# Display the shape of the prepared data set\n",
    "print(\"Prepared data shape:\\n\", prepared_data.shape)\n",
    "# Display the first few rows of the prepared data set\n",
    "print(\"Prepared data first rows:\\n\", prepared_data.head())\n",
    "\n",
    "# Define the feature columns and target columns\n",
    "feature_columns = ['Temperatur_Kategorie', 'Bewoelkung']\n",
    "target_columns = pivot_dataf.columns[pivot_dataf.columns.str.startswith('Warengruppe_')]\n",
    "\n",
    "print(\"Feature Columns:\\n\", feature_columns)\n",
    "print(\"Target Columns:\\n\", target_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split des Datensatzes in Trainings und Validierungsdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definieren der Datumsgrenzen\n",
    "train_start_date = '2013-07-01'\n",
    "train_end_date = '2017-07-31'\n",
    "validation_end_date = '2018-07-31'\n",
    "\n",
    "# Split the data into training (3 years) and validation (1 year)\n",
    "train_data = pivot_dataf[(pivot_dataf['Datum']>= train_start_date) & (dataf['Datum'] <= train_end_date)]\n",
    "val_data = pivot_dataf[(pivot_dataf['Datum']> train_end_date) & (dataf['Datum'] <= validation_end_date)]\n",
    "\n",
    "# Überprüfen der Dimensionen der Datensätze\n",
    "print(\"Training dataset dimensions:\", train_data.shape)\n",
    "print(\"Validation dataset dimensions:\", val_data.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
