{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the new dataset is saved as 'bakery_sales.csv'\n",
    "# The dataset has columns: 'date', 'category', 'sales_volume', 'temperature', 'cloud_coverage'\n",
    "data = pd.read_csv(\"path/to/your/bakery_sales.csv\")\n",
    "\n",
    "# Convert the date column to datetime\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "\n",
    "# Pivot the data to have one row per date and one column per category\n",
    "pivot_data = data.pivot_table(index='date', columns='category', values='sales_volume').reset_index()\n",
    "\n",
    "# Add temperature and cloud coverage columns to the pivoted data\n",
    "pivot_data = pivot_data.merge(data[['date', 'temperature', 'cloud_coverage']].drop_duplicates(), on='date')\n",
    "\n",
    "# Display the first few rows of the prepared data\n",
    "print(pivot_data.head())\n",
    "\n",
    "# Ensure no missing values by filling them with zeros\n",
    "pivot_data.fillna(0, inplace=True)\n",
    "\n",
    "# Define the feature columns and target columns\n",
    "feature_columns = ['temperature', 'cloud_coverage']\n",
    "target_columns = pivot_data.columns[pivot_data.columns.str.startswith('category_')]\n",
    "\n",
    "# Split the data into training (3 years) and validation (1 year)\n",
    "split_date = pivot_data['date'].max() - pd.DateOffset(years=1)\n",
    "train_data = pivot_data[pivot_data['date'] < split_date]\n",
    "val_data = pivot_data[pivot_data['date'] >= split_date]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
