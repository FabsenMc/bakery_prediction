{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcixbGdQH6YZ"
      },
      "source": [
        "### Import Libraries and Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VPqpxN_gH6Yc",
        "outputId": "1b1b105e-0f9d-47dd-8da1-9abe5ec018ed"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Import Data\n",
        "data = pd.read_csv(\"/workspaces/bakery_prediction/0_DataPreparation/dataf_knn.csv\", usecols=['Datum', 'Warengruppe', 'Temperatur', 'Wochentag_MDMDFSS', 'Verbraucherpreisindex', 'FerienSH', 'Feiertag', 'Jahreszeit_FSHW', 'Wochenende', 'Windgeschwindigkeit', 'Wettercode'])\n",
        "\n",
        "\n",
        "data['Temperatur_Cluster'] = 0  # Alle Werte auf 0 setzen\n",
        "\n",
        "# Setzen Sie die Werte in 'Temperatur_Cluster' basierend auf den Werten in 'Temperatur'\n",
        "data['Temperatur_Cluster'] = data['Temperatur'].apply(lambda x: 1 if x < 10 else (2 if x < 20 else 3))\n",
        "\n",
        "# Konvertieren Sie die 'Datum'-Spalte in ein Datumsformat\n",
        "data['Datum'] = pd.to_datetime(data['Datum'])\n",
        "\n",
        "data['Jahreszeit'] = 0  # Alle Werte auf 0 setzen\n",
        "\n",
        "# Setzen Sie die Werte in 'Jahreszeit' auf 1, wenn das Datum von Dezember bis Februar liegt\n",
        "data['Jahreszeit'] = data['Datum'].apply(lambda x: 4 if x.month in [12, 1, 2] else 1 if x.month in [3, 4, 5] else 2 if x.month in [6, 7, 8] else 3)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUWjuQjFH6Yd"
      },
      "source": [
        "### Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7UlKuUmTH6Ye",
        "outputId": "f36d296e-50e6-4144-ba7a-12fddcd47125"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warengruppe           category\n",
            "Temperatur_Cluster    category\n",
            "Jahreszeit            category\n",
            "dtype: object\n",
            "Unique Values:\n",
            " Warengruppe           [4, 3, 2, 1, 5, 6]\n",
            "Categories (6, int64): [1, ...\n",
            "Temperatur_Cluster           [1, 2, 3]\n",
            "Categories (3, int64): [1, 2, 3]\n",
            "Jahreszeit             [4, 1, 2, 3]\n",
            "Categories (4, int64): [1, 2, 3, 4]\n",
            "dtype: object\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "\"['Weihnachtsmarkt'] not in index\"",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[1;32m/workspaces/bakery_prediction/3_Model/Linda NN/Bjoern_neural_net_data_preparation_LH.ipynb Zelle 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bmusical-guacamole-976gp9rgw967hp955/workspaces/bakery_prediction/3_Model/Linda%20NN/Bjoern_neural_net_data_preparation_LH.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m features \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mget_dummies(data[categorical_features], drop_first\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bmusical-guacamole-976gp9rgw967hp955/workspaces/bakery_prediction/3_Model/Linda%20NN/Bjoern_neural_net_data_preparation_LH.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# Include any numeric columns that are not categorical\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://codespaces%2Bmusical-guacamole-976gp9rgw967hp955/workspaces/bakery_prediction/3_Model/Linda%20NN/Bjoern_neural_net_data_preparation_LH.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m numerical_features \u001b[39m=\u001b[39m data[[\u001b[39m'\u001b[39;49m\u001b[39mFerienSH\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mFeiertag\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mWeihnachtsmarkt\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mWochenende\u001b[39;49m\u001b[39m'\u001b[39;49m]] \n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bmusical-guacamole-976gp9rgw967hp955/workspaces/bakery_prediction/3_Model/Linda%20NN/Bjoern_neural_net_data_preparation_LH.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# Construct the prepared data set including the dependent variable ('label')\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bmusical-guacamole-976gp9rgw967hp955/workspaces/bakery_prediction/3_Model/Linda%20NN/Bjoern_neural_net_data_preparation_LH.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m prepared_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([data[[\u001b[39m'\u001b[39m\u001b[39mUmsatz\u001b[39m\u001b[39m'\u001b[39m]], features, numerical_features], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mdropna()\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4107\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> 4108\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[1;32m   4110\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4111\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6249\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[0;32m-> 6252\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['Weihnachtsmarkt'] not in index\""
          ]
        }
      ],
      "source": [
        "# Define categorical features\n",
        "categorical_features = ['Warengruppe', 'Temperatur_Cluster', 'Jahreszeit']\n",
        "\n",
        "# Inspect data types and unique values for categorical columns\n",
        "print(data[categorical_features].dtypes)\n",
        "print(\"Unique Values:\\n\",data[categorical_features].apply(lambda x: x.unique()))\n",
        "\n",
        "# Ensure categorical columns are treated as categories\n",
        "for col in categorical_features:\n",
        "    data[col] = data[col].astype('category')\n",
        "\n",
        "# Encode categorical variables using pd.get_dummies\n",
        "features = pd.get_dummies(data[categorical_features], drop_first=True, dtype=int)\n",
        "\n",
        "# Include any numeric columns that are not categorical\n",
        "numerical_features = data[['FerienSH', 'Feiertag', 'Weihnachtsmarkt', 'Wochenende']] \n",
        "\n",
        "# Construct the prepared data set including the dependent variable ('label')\n",
        "prepared_data = pd.concat([data[['Umsatz']], features, numerical_features], axis=1).dropna()\n",
        "\n",
        "# Handle missing values by removing rows with any missing values\n",
        "prepared_data = prepared_data.dropna()\n",
        "\n",
        "# Display the shape of the prepared data set\n",
        "print(prepared_data.shape)\n",
        "# Display the first few rows of the prepared data set\n",
        "prepared_data.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToWs4RU9H6Ye"
      },
      "source": [
        "### Selection of Training and Validation Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9eIQ_keGH6Ye",
        "outputId": "593e8cc3-e9fe-4ea5-88c2-406b7355198d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training features dimensions: (8349, 618)\n",
            "Validation features dimensions: (2087, 618)\n",
            "\n",
            "Training labels dimensions: (8349, 1)\n",
            "Validation labels dimensions: (2087, 1)\n"
          ]
        }
      ],
      "source": [
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Shuffle the data\n",
        "prepared_data = prepared_data.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# Calculate the number of rows for each dataset\n",
        "n_total = len(prepared_data)\n",
        "# n_training = int(0.7 * n_total)\n",
        "n_training = int(0.8 * n_total)\n",
        "n_validation = int(0.20 * n_total)\n",
        "\n",
        "# Split the features and labels for training, validation, and test\n",
        "training_data = prepared_data.iloc[:n_training]\n",
        "validation_data = prepared_data.iloc[n_training:n_training+n_validation]\n",
        "# test_data = prepared_data.iloc[n_training+n_validation:]\n",
        "\n",
        "# Separating features and labels\n",
        "training_features = training_data.drop('Umsatz', axis=1)\n",
        "validation_features = validation_data.drop('Umsatz', axis=1)\n",
        "# test_features = test_data.drop('Umsatz', axis=1)\n",
        "\n",
        "training_labels = training_data[['Umsatz']]\n",
        "validation_labels = validation_data[['Umsatz']]\n",
        "# test_labels = test_data[['Umsatz']]\n",
        "\n",
        "# Print dimensions of the dataframes\n",
        "print(\"Training features dimensions:\", training_features.shape)\n",
        "print(\"Validation features dimensions:\", validation_features.shape)\n",
        "# print(\"Test features dimensions:\", test_features.shape)\n",
        "print()\n",
        "print(\"Training labels dimensions:\", training_labels.shape)\n",
        "print(\"Validation labels dimensions:\", validation_labels.shape)\n",
        "# print(\"Test labels dimensions:\", test_labels.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9OqnXDRH6Yf"
      },
      "source": [
        "#### Data Export"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1AX0OVMcH6Yf"
      },
      "outputs": [],
      "source": [
        "# Create subdirectory for the pickle files\n",
        "subdirectory = \"pickle_data\"\n",
        "os.makedirs(subdirectory, exist_ok=True)\n",
        "\n",
        "# Export of the prepared data to subdirectory as pickle files\n",
        "training_features.to_pickle(f\"{subdirectory}/training_features.pkl\")\n",
        "validation_features.to_pickle(f\"{subdirectory}/validation_features.pkl\")\n",
        "# test_features.to_pickle(f\"{subdirectory}/test_features.pkl\")\n",
        "training_labels.to_pickle(f\"{subdirectory}/training_labels.pkl\")\n",
        "validation_labels.to_pickle(f\"{subdirectory}/validation_labels.pkl\")\n",
        "# test_labels.to_pickle(f\"{subdirectory}/test_labels.pkl\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
